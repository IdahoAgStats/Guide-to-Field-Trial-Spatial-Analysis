[
["index.html", "Incorporating Spatial Analysis into Agricultural Field Experiments. Section 1 Preface 1.1 Tutorial goals 1.2 Prerequisites 1.3 Packages we will use 1.4 Acknowledgements 1.5 License", " Incorporating Spatial Analysis into Agricultural Field Experiments. Julia Piaskowski 2019-07-26 Section 1 Preface 1.1 Tutorial goals To help people conducting planned agricultural field trials to understand and incorporate spatial variation routinely into analysis of field trials. current resources are focused on geospatia appications - LANDSAT data across large area, point information on soils and geology, and other information that typiically requiresa a moderate to deep understanding of obht GIS tools and spatial analytica techniques. Furthermore, there is not a comprehensive one-stop-shop for spatial analytical techniques for fied experiments that is also freely available. 1.2 Prerequisites In order to run the scripts in this demonstration, you will to download R, avaiable free through the Comprehensive R Archive Network. While this is sufficient for running R scripts, You may also find it hepful to use RStudio, which provides a nice graphical user interface for R. RStudio can be downloaded here. If you already have R installed, please make sure you have version 3.5.0 or newer. This demonstration is not intended to provide instructions on general R usage. However, There are numerous web resources for learning the Basics of R: 1.3 Packages we will use 1.4 Acknowledgements 1.5 License 1.5.0.1 OLD STUFF This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],
["intro.html", "Section 2 Introduction 2.1 Why care about spatial variation? 2.2 Diagnosing spatial autocorrelation", " Section 2 Introduction 2.1 Why care about spatial variation? Goal in this case is to understand and account for spatial variation. These are lattice data 2.2 Diagnosing spatial autocorrelation Spatial correlation is similarity of plots that are close to one another. Larger spatial gradients need to modelled indpendently - perhaps through blocking. 2.2.1 Moran’s I Moran’s I, sometimes called “Global Moran’s I” is similar like a correlation coefficient. It is a test for correation between units (plots in our case). \\[ I = \\frac{N}{W}\\frac{\\sum_i \\sum_j w_{ij} (x_i - \\bar{x})(x_j - \\bar{x})}{\\sum_i(x_i - \\bar{x})^2} \\qquad i \\neq j\\] Where N is total number of spatial locations indexed by \\(i\\) and \\(j\\), x is the variable of interest, \\(w_{ij}\\) are a spatial weights between each \\(i\\) and \\(j\\), and W is the sum of all weights. The expected values of Moran’s I is \\(-1/(N-1)\\). Values greater than that indicate positive spatial correlation (areas close to each other are similar), while values less than the expected Moran’s I indicate dissimilarity as spatial distance between points decreases. There are several options for defining adjacent neighbors and how to weight each neighbors’s influence. The two common configuations for defininig neighbors are the rook and queen configurations. These are exactly what their chess analogy suggest: “rook” defines neighbhors in an row/column fashion, while “queen” defines nieghbors in a row/column configuation an also neighbors located diagonally at a 45 degree angle from the row/column neighbors. Determining this can be somewhat complicated when working with irregularly-placed data (e.g. county seats), but is quite unambiguous for gridded data commonly seen in panned field experiments: Another test for diagnosing spatial correlation is Geary’s C: \\[ I = \\frac{(N -1)}{2W}\\frac{\\sum_i \\sum_j w_{ij} (x_i - x_j)^2}{\\sum_i(x_i - \\bar{x})^2} \\qquad i \\neq j\\] These terms have the same meaning in Moran’s I. The expected value of Geary’s C is 1. Values higher than 1 indicate positive spatial correlation and less than 1 indicate negative spatial correlation. 2.2.2 Empirical variogram &amp; semivariance An empirical varigram is a visual tool for understanding how error terms are related to each other over spatial distance. It relies on semivariance (\\(\\gamma\\)), a statistic expressing variance as a function of pairwise distances between data points at points \\(i\\) and \\(j\\). \\[\\gamma(h) = \\frac{1}{2|N(h)|}\\sum_{N(h)}(x_i - x_j)^2\\] Semivariances are binned for distance intervals. The average values for semivariance and distance interval can be fit to correlated error models such a exponential, spherical, gaussian and Matér. How to dothis is explored further in section 2 of this guide. Three important concepts of an empirical variogram are nugget, sill and range Example Empirical Variogram range = distance up to which is there is spatial correlation sill = uncorrelated variance of the variable of interest nugget = measurement error,short-distance spatial variance and other unaccounted for variance 2 other concepts: partial sill = sill - nugget nugget effect = the nugget/sill ratio, interpreted opposite of \\(r^2\\) 2.2.2.1 OLD STUFF You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter ??. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2019) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["spatial-models-ch2-bg.html", "Section 3 Spatial Models {ch2-bg} 3.1 Correlated Error Models 3.2 Nearest Neighbor Approaches 3.3 Trend Analysis", " Section 3 Spatial Models {ch2-bg} This section contains some of the background behind why spatial models are used and how they work. Understanding this section is not essential, but it is extremely helpful. This section relies on information introduced in part I, s please make sure you have read that section, especially if you are new to empirical variograms and spatial statistics. General linear statistical models are commonly modeled as thus: \\[Y_i = \\beta_0 + X_i\\beta_1 + \\epsilon_i\\] \\(\\beta_1\\) is a slope describing the relationship between a continuous variable and the dependent variable, \\(Y_i\\). If \\(X_i\\) is a categorical variable, such as a crop variety, then there will be \\(p-1\\) slopes estimated, where p is the number of unique treatements levels in \\(X\\). The error terms, \\(\\epsilon_i\\) are assumed normally distributed with a mean of zero and a variance of \\(\\sigma^2\\) : \\[e_i ~\\sim N(0, \\sigma^2)\\] The error terms, or residuals, are assumed to be identically and independently distributed (abbreviated as “iid”). This implies a constant variance of the error terms and zero covariance between residuals. If N = 3, the expanded model looks like this: \\[\\left[ {\\begin{array}{ccc} Y_1\\\\ Y_2\\\\ Y_3 \\end{array} } \\right] = \\beta_0 + \\left[ {\\begin{array}{ccc} X_1\\\\ X_2\\\\ X_3 \\end{array} } \\right] \\beta_1 + \\left[ {\\begin{array}{ccc} \\epsilon_1\\\\ \\epsilon_2\\\\ \\epsilon_3 \\end{array} } \\right] \\] \\[e_i ~\\sim N \\Bigg( 0, \\left[ {\\begin{array}{ccc} \\sigma^2 &amp; 0 &amp; 0 \\\\ 0 &amp; \\sigma^2 &amp; 0\\\\ 0 &amp; 0 &amp; \\sigma^2\\end{array} } \\right] \\Bigg) \\] If spatial variation is present, the off-diagonals of the variance-covariance matrix are not zero - hence the error terms are not independently distributed. As a result, hypotheses test and parameter estimates from uncorrected linear models will provide erroneous results. 3.1 Correlated Error Models 3.1.1 Distance-based Correlation Error Models There are mathematical tools for modelling how error terms are correlated with each other based on pairwise physical distance between observations. These models can be used to weight observations. Often, the data are assumed to be isotropic, where distance but not direction impacts error spatial correlation There are several methods for estimating the semivariance as a direct function of distance. 3.1.1.1 Exponential Model \\[ \\gamma (h)\\left\\{ {\\begin{array}{cc} 0 &amp; h = 0\\\\ C_0+C_1 \\left [ 1-e^{-(\\frac{h}{r})} \\right] &amp; h &gt; 0 \\end{array} } \\right. \\] where \\[ C_0 = nugget \\\\ C_1 = partial \\: sill \\\\ r = range\\] Figure 3.1: Exponential Model \\(3r = r_p\\) is the “practical range”, which is 95% of the true value for \\(C_1\\). 3.1.1.2 Gaussian (a squared version of the exponential model) \\[ \\gamma (h)\\left\\{ {\\begin{array}{cc} 0 &amp; h = 0\\\\ C_0+C_1 \\left [ 1-e^{-(\\frac{h}{r})^2} \\right] &amp; h &gt; 0 \\end{array} } \\right. \\] where \\[ C_0 = nugget \\\\ C_1 = partial \\: sill \\\\ r = range\\] Figure 3.2: Gaussian Model \\(\\sqrt 3r = r_p\\) is the “practical range”, which is 95% of the true value for \\(C_1\\). 3.1.1.3 Spherical model \\[ \\gamma (h) = \\left\\{ {\\begin{array}{cc} 0 &amp; h = 0\\\\ C_0+C_1 \\left[ \\frac{3h}{2r}-0.5\\bigg( \\frac{h}{r}\\bigg)^3 \\right] &amp; 0 &lt;h \\leq r \\\\ C_0 + C_1 &amp; h &gt; r \\end{array} } \\right. \\] where \\[ C_0 = nugget \\\\ C_1 = partial \\: sill \\\\ r = range\\] Figure 3.3: Spherical Model 3.1.1.4 Other correlated error distance models There are many more models - Matérn, Cauchy, Logistic - that may describe spatial correlation in a data set. There are two addition models that have no range or sill, the linear model and power model. If your data fits these, consider doing a trend analysis. 3.1.1.5 Linear model \\[ \\gamma (h)=\\left\\{ {\\begin{array}{cc} 0 &amp; h = 0\\\\ C_0+C_1h &amp; h &gt; 0 \\end{array} } \\right. \\] where \\[ C_0 = nugget \\\\ C_1 = slope \\] Figure 3.4: Linear Error Model There is no sill or range in the linear model, so the variance will continue to increase as a function of distance. 3.1.1.6 Power Model \\[ \\gamma (h)=\\left\\{ {\\begin{array}{cc} 0 &amp; h = 0\\\\ C_0+C_1h^\\lambda &amp; h &gt; 0 \\end{array} } \\right. \\] where \\[ 0 \\leq \\lambda &lt;\\leq 2 \\\\ C_0 = nugget \\\\ C_1 = scaling \\: factor \\] Figure 3.5: Power Model When \\(\\lambda = 1\\), that is equivalent to the linear model. Example above is when \\(\\lambda = 0.5\\) (i.e. a square-root transformation) and \\(C_1 = 1\\). There is also no sill or range in the power model. 3.1.2 Correlated Error Models for Gridded Data Planned field experiments often have the advantage of being arranged in regular grid pattern that can be adequately described using Euclidian space. This simplifies aspects of understanding how error terms are related by distance since the data occur in evenly spaced increments. Furthermore, in many agricultural trials, there may be no interest in spatial interpolation between units. Some of these models work with irregular data, but the models presented are simplified forms when experimental units are arranged in regular grid. For example, imagine an experiment consisting of 8 plots (plot = the experiment units) arranged in 2 rows, each with 4 ranges with this layout: The statistical model for that experiment: \\[ \\left[ {\\begin{array} \\ Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_n \\end{array} } \\right] = \\beta_0 + \\left[ {\\begin{array} \\ X_1 \\\\ X_2 \\\\ \\vdots \\\\ X_n \\end{array} } \\right] \\beta_1 + \\left[ {\\begin{array} \\ \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{array} } \\right] \\] \\(X\\beta\\) refer to independent variable effects. This same model is also often presented in an abbreviated matrix form: \\[ \\mathbf{Y = X\\beta + \\epsilon}\\] 3.1.2.1 Auto-regressive Model (AR1) This assumes that variance can be modelled as exponential function based on unit distance (e.g. row or range), either in a single direction or anistropic. The AR1 structure across 2 rows is modeled as thus: \\[\\mathbf { V_{AR(1)row}} = \\sigma^2 \\left[ {\\begin{array}{cc} 1 &amp; \\rho \\\\ \\rho &amp; 1 \\end{array} } \\right] \\otimes \\mathbf{I_4} \\] This covariance model describes the correlation of observations in the row direction only. And similarily the AR1 structure across 4 ranges is modeled as thus: \\[ \\mathbf {V_{AR(1)range}} = \\sigma^2 \\mathbf{I_4} \\otimes \\left[ {\\begin{array}{cccc} 1 &amp; \\rho &amp; \\rho^2 &amp; \\rho^3 \\\\ \\rho &amp; 1 &amp; \\rho &amp; \\rho^2 \\\\ \\rho^2 &amp; \\rho &amp; 1 &amp; \\rho \\\\ \\rho^3 &amp; \\rho^2 &amp; \\rho &amp; 1 \\end{array} } \\right] \\] This covariance model describes the correlation of observations in the range direction only. In combined AR1xAR1 model, the parameter, \\(\\rho\\) may need to estimated separated across the row and column directions depending on the shape of the plots and site-specific field variation. Very rectangular plots are likely to require a separate estimate of the \\(\\rho\\) parameter for each direction. $$ = ^2 $$ Note: \\(\\rho_1\\) and \\(\\rho_2\\) are the parameter estimate for \\(V_{AR1(1) row}\\) and \\(V_{AR(1)range}\\), respectively. Please note that these error models are for modelling localised variation based on physical proximity. It is assumed that eventually a distance in the experiment can be reached in which 2 observations can be treated independent. If there are spatial trends that extend along the entire scope of an experiment (for instance, due to position on a slope), then an additional trend analysis should be conducted. 3.2 Nearest Neighbor Approaches These approaches look use information from adjacent plots to adjust for spatial auto-correlation. 3.2.1 Spatial Durbin Approach This one add the average of values the neighboring independent variables to the model: \\[y = X\\beta + WX\\theta + \\epsilon \\] 3.2.2 Spatial Autoregressive (SAR) Sometimes called a “lag” model, the SAR model uses correlations with neighboring plots dependent variable to predict Y. The auto-regressive model explicitly models correlations between neighboring points. \\[\\mathbf{Y = \\rho W Y + X\\beta + \\epsilon} \\] While this may look strange, \\(\\mathbf{W}\\) is an \\(n\\) x \\(n\\) matrix weighting the neighbors with a diagonal of zero so the value at \\(i=j\\), that is \\(Y_{ijk}\\) itself, is not used on the right-hand side to predict \\(Y_{ijk}\\) on the left-hand side of the equation. The error terms are assumed iid. 3.2.3 Spatial Error Model (SEM) This is also refereed to as the “moving average model” and is quite similar to auto-regressive model. Auto-regressive models a variables’s spatial dependence on nearby experimental units. \\[\\mathbf {Y= X\\beta + u} \\\\ \\mathbf {u = \\lambda W + \\nu}\\] Where \\(\\mathbf{u}\\) incorporates both the normally-distributed iid error and spatially correlated error. Like in SAR, \\(\\mathbf{W}\\) is a matrix of spatial weights and \\(\\lambda\\) is a parameter describing autocorrelation of the error terms. 3.2.4 ARIMA The AR1 and MA1 models can be combine into one: \\[ y = X\\beta + \\rho W_1y+u \\\\ u = \\lambda W_2 + \\nu \\] On Weights Setting weights of neighbors is dealt with in the next chapter4, 3.3 Trend Analysis 3.3.1 Row, column and combined and row plus column trends. Experiment wide-trends should be modeled with directional trend models. These are comparatively simple models: \\[Y_{ijk} = \\beta_0 + X_{i1}\\beta_1 + Row_{j2}\\beta_2 + Range_{k3}\\beta_3 +\\epsilon_{ijk}\\] If the assumption of independent, normal, and identical errors are met, then this model will suffice. If spatial variation is still present, additional measures will need to be taken. 3.3.2 Splines There is a rich field of research on using localised splines to model field heterogeneity. These models are complex and hence not described. More resources can be found in the references section. "],
["ch3.html", "Section 4 Example Analysis 4.1 Load Data 4.2 Test for Spatial Correlation 4.3 Empirical Variogram Fitting", " Section 4 Example Analysis 4.1 Load Data This tutorial uses the Nebraska Interstate wheat trials, first published by Stroup et al in 1991 and reused extensively in field spatial variation studies. library(agridat); library(dplyr); library(tidyr) data(&quot;stroup.nin&quot;) Nin &lt;- stroup.nin %&gt;% mutate(col.width = col * 1.2, row.length = row * 4.3) %&gt;% mutate(name = case_when(is.na(as.character(rep)) ~ NA_character_, TRUE ~ as.character(gen))) %&gt;% arrange(col, row) %&gt;% mutate(plot = 1:n()) Nin.na &lt;- filter(Nin, !is.na(rep)) 4.1.1 Examine Data head(Nin) ## gen rep yield col row col.width row.length name plot ## 1 Lancer &lt;NA&gt; NA 1 1 1.2 4.3 &lt;NA&gt; 1 ## 2 NE83407 R1 19.40 1 2 1.2 8.6 NE83407 2 ## 3 Buckskin R1 29.85 1 3 1.2 12.9 Buckskin 3 ## 4 NE87612 R1 28.15 1 4 1.2 17.2 NE87612 4 ## 5 Vona R2 26.80 1 5 1.2 21.5 Vona 5 ## 6 NE87512 R2 20.20 1 6 1.2 25.8 NE87512 6 str(Nin) ## &#39;data.frame&#39;: 242 obs. of 9 variables: ## $ gen : Factor w/ 56 levels &quot;Arapahoe&quot;,&quot;Brule&quot;,..: 12 16 3 44 56 41 34 7 3 44 ... ## $ rep : Factor w/ 4 levels &quot;R1&quot;,&quot;R2&quot;,&quot;R3&quot;,..: NA 1 1 1 2 2 3 3 3 4 ... ## $ yield : num NA 19.4 29.9 28.1 26.8 ... ## $ col : int 1 1 1 1 1 1 1 1 1 1 ... ## $ row : int 1 2 3 4 5 6 7 8 9 10 ... ## $ col.width : num 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 ... ## $ row.length: num 4.3 8.6 12.9 17.2 21.5 25.8 30.1 34.4 38.7 43 ... ## $ name : chr NA &quot;NE83407&quot; &quot;Buckskin&quot; &quot;NE87612&quot; ... ## $ plot : int 1 2 3 4 5 6 7 8 9 10 ... This data set actually has no missing data – this is a balanced trial. However, there are empty fill plot with no data which creates some issues regarding NA handling. Plot raw data as it appeared in the field: library(ggplot2); library(desplot) ggplot(Nin, aes(x = row, y = col)) + geom_tile(aes(fill = yield), col = &quot;white&quot;) + #geom_text(aes(label = name)) + geom_text(aes(label = plot)) + geom_tileborder(aes(group = 1, grp = rep), lwd = 1.2) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;blue&quot;) + scale_x_continuous(breaks = seq(1,max(Nin$row), 1)) + scale_y_continuous(breaks = 1:max(Nin$col)) + labs(x = &quot;row&quot;, y = &quot;column&quot;, title = &quot;field plot layout&quot;) + theme_classic() + theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14), legend.title = element_text(size = 14), legend.text = element_text(size = 12)) Black lines delineate the blocks. library(rayshader) options(cores = 3) It’s also helpful to plot raw response data: par(mfrow=c(1,3)) boxplot(yield ~ rep, data = Nin, xlab = &quot;rep&quot;, ylab = &quot;yield (bu/acres)&quot;, col = &quot;red2&quot;, main = &quot;yield across blocks&quot;) boxplot(yield ~ row, data = Nin, xlab = &quot;row&quot;, ylab = &quot;yield (bu/acres)&quot;,col = &quot;dodgerblue2&quot;, main = &quot;yield across rows&quot;) boxplot(yield ~ col, data = Nin, col = &quot;gold&quot;, xlab = &quot;column&quot;, ylab = &quot;yield (bu/acres)&quot;,main = &quot;yield across columns&quot;) par(mfrow=c(1,1)) 4.2 Test for Spatial Correlation 4.2.1 Moran’s I First, run a standard linear model of the experiment: library(nlme); library(car) nin.lme &lt;- lme(yield ~ gen, random = ~1|rep, data = Nin, na.action = na.exclude) Anova(nin.lme, type = &quot;2&quot;) ## Analysis of Deviance Table (Type II tests) ## ## Response: yield ## Chisq Df Pr(&gt;Chisq) ## gen 48.152 55 0.7317 Next, establish and weight neighbors. In this example, only adjacent neighbors in the rook formation are used and are weighted proportionally according to their representation as neighbors to an individual. That is, if a unit has 4 adjacent neighbors, each neighbor is weighted as 0.25. If there are only two neighbors, each is weighted as 0.5. The function cell2nb is a simplified function for setting neighbors when working with data laid out in a regular grid, which is a common feature of many agricultural field trials. library(spdep) xy.rook &lt;- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type=&quot;rook&quot;) # make sur your data sorted by the variables assigned to row and col (in that order), and there is one and only one observation in the data set for each unique row/col combination. Even missing plots need a row Rook adjacency plot for the NIN data library(sf) plot(xy.rook, coords = st_multipoint(matrix(c(Nin$col, Nin$row), ncol = 2))) Each observation considers “neighbors” to be those which touch the cell in a row or column oriention, but not diagonal. Conduct Moran’s test via standard t-test and using MC sampling. resid.lme &lt;- residuals(nin.lme) names(resid.lme) &lt;- Nin$plot moran.test(resid.lme, nb2listw(xy.rook), na.action = na.exclude) ## ## Moran I test under randomisation ## ## data: resid.lme ## weights: nb2listw(xy.rook) ## omitted: 1, 12, 23, 34, 45, 56, 59, 67, 78, 89, 100, 108, 111, 122, 133, 144, 155, 204 ## ## Moran I statistic standard deviate = 8.1602, p-value &lt; 2.2e-16 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## 0.402504491 -0.004484305 0.002487522 moran.mc(resid.lme, nb2listw(xy.rook), 999, na.action = na.exclude) ## ## Monte-Carlo simulation of Moran I ## ## data: resid.lme ## weights: nb2listw(xy.rook) ## omitted: 1, 12, 23, 34, 45, 56, 59, 67, 78, 89, 100, 108, 111, 122, 133, 144, 155, 204 ## number of simulations + 1: 1000 ## ## statistic = 0.4025, observed rank = 1000, p-value = 0.001 ## alternative hypothesis: greater Plot Spatial dependence of resids library(purrr) res.nn1 &lt;- map_dbl(xy.rook, function(j) mean(resid.lme[j])) c &lt;- signif(cor(resid.lme, res.nn1, use = &quot;pairwise.complete.obs&quot;), 2) plot(x = resid.lme, y = res.nn1, main = paste0(&quot;r = &quot;, c), xlab = &quot;residual&quot;, ylab = &quot;average residual of neighbor (rook)&quot;) 4.2.2 Note on Geary’s C At this time, the spdep function geary.test() for Geary’s C does not handle missing spatial points. This is area to contribute to! The 4.3 Empirical Variogram Fitting First, create a spatial object by adding spatial coordinates to an ordinary data frame. I like to use the actual units of the plots since they are exaggerated rectangals (meters in this example). Nin.spatial &lt;- Nin.na coordinates(Nin.spatial) &lt;- ~ col.width + row.length class(Nin.spatial) ## [1] &quot;SpatialPointsDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; Set the maximum distance for calculating the variogram model (which is one-half the maximum distance between two points). max_dist = 0.6*max(dist(coordinates(Nin.spatial))) max_dist ## [1] 29.90409 Calculate semivariance for an istropic model and plot the variogram. library(gstat) resid.var1 &lt;- variogram(yield ~ rep + gen, cutoff = max_dist, width = max_dist/20, # 20 is the number of bins data = Nin.spatial) plot(resid.var1) Test out correlated error models: First, set the starting nugget values as the minimum of the semi-variance. There is likely more sophicated methods to establish the starting value for nugget, but I have found that extracting the minimum value of the semivariance to work well as a starting point. nugget_start &lt;- min(resid.var1$gamma) Establish models for variogram fitting. Nin.vgm1 &lt;- vgm(model = &quot;Exp&quot;, nugget = nugget_start) # exponential Nin.vgm2 &lt;- vgm(model = &quot;Sph&quot;, nugget = nugget_start) # spherical Nin.vgm3 &lt;- vgm(model = &quot;Gau&quot;, nugget = nugget_start) # Gaussian Fit the variograms to the data: Nin.variofit1 &lt;- fit.variogram(resid.var1, Nin.vgm1) Nin.variofit2 &lt;- fit.variogram(resid.var1, Nin.vgm2) Nin.variofit3 &lt;- fit.variogram(resid.var1, Nin.vgm3) Look at the results! (this is fun) plot(resid.var1, Nin.variofit1, main = &quot;Exponential model&quot;) plot(resid.var1, Nin.variofit2, main = &quot;Spherical model&quot;) plot(resid.var1, Nin.variofit3, main = &quot;Gaussian model&quot;) How to pick the best one? Looking at how well each captures the error is the best approach. The attribute “SSError” indicates how well each model was able to predict the binned error terms as a function of distance. print(&quot;Exponential&quot;); attr(Nin.variofit1, &quot;SSErr&quot;) ## [1] &quot;Exponential&quot; ## [1] 1129.799 print(&quot;Spherical&quot;); attr(Nin.variofit2, &quot;SSErr&quot;) ## [1] &quot;Spherical&quot; ## [1] 1012.76 print(&quot;Gaussian&quot;); attr(Nin.variofit3, &quot;SSErr&quot;) ## [1] &quot;Gaussian&quot; ## [1] 752.5491 Nin.Variofit3 had the lowest error terms, corresponding to the Gaussian model. Results from the empirical variogram: Nin.variofit3 ## model psill range ## 1 Nug 20.04106 0.00000 ## 2 Gau 22.04013 12.19921 The variogram parameters can be easily extracted from this table: nugget &lt;- Nin.variofit3$psill[1] # &quot;measurement error&quot; range &lt;- Nin.variofit3$range[2] # distance to establish independence between data points sill &lt;- sum(Nin.variofit3$psill) # maximum semivariance Try out Anistropic Models: Reestablish models for variogram fitting. Nin.vgm1a &lt;- vgm(model = &quot;Exp&quot;, anis = c(90, 0.5)) # 90 refers to the angle of the main direction and 0.5 creates a second 90 degree axis of variability to estimate Nin.vgm2a &lt;- vgm(model = &quot;Sph&quot;, anis = c(90, 0.5)) Nin.vgm3a &lt;- vgm(model = &quot;Gau&quot;, anis = c(90, 0.5)) Fit the variograms to the data: Nin.variofit1a &lt;- fit.variogram(resid.var1, Nin.vgm1a) Nin.variofit2a &lt;- fit.variogram(resid.var1, Nin.vgm2a) Nin.variofit3a &lt;- fit.variogram(resid.var1, Nin.vgm3a) print(&quot;Exponential&quot;); attr(Nin.variofit1a, &quot;SSErr&quot;) ## [1] &quot;Exponential&quot; ## [1] 8387.429 print(&quot;Spherical&quot;); attr(Nin.variofit2a, &quot;SSErr&quot;) ## [1] &quot;Spherical&quot; ## [1] 9448.75 print(&quot;Gaussian&quot;); attr(Nin.variofit3a, &quot;SSErr&quot;) ## [1] &quot;Gaussian&quot; ## [1] 19319.19 Error terms are considerably higher than in the anistropic model! plot(resid.var1, Nin.variofit1a, main = &quot;Exponential model&quot;) Hmm, that plot is not very convincing. In this field trial, there is evidence spatial correlation as a function of distance, but there is not evidence that spatial autocorrelation is impacted by the direction. It’s important to remember these methods are intended to describe localised spatial correlation. Field-wide spatial gradients should be modelled as a separate trend. "],
["ch4.html", "Section 5 Applying Spatial Covariates 5.1 Prep work 5.2 Correlated Errors I: spatial distance 5.3 Nearest Neighbor Approaches 5.4 p-Splines", " Section 5 Applying Spatial Covariates library(agridat); library(dplyr); library(tidyr) data(&quot;stroup.nin&quot;) Nin &lt;- stroup.nin %&gt;% mutate(col.width = col * 1.2, row.length = row * 4.3) %&gt;% mutate(name = case_when(is.na(as.character(rep)) ~ NA_character_, TRUE ~ as.character(gen))) %&gt;% arrange(col, row) Nin.na &lt;- filter(Nin, !is.na(rep)) Nin.spatial &lt;- Nin.na coordinates(Nin.spatial) &lt;- ~ col.width + row.length Once spatial autocorrelation has been identified in field trials, the next logical step is to employ a modelling technique that will reduce the impact of spatial varition on the final estiamtes from the analysis. 5.1 Prep work As a reminder, the first thing is to run a standard linear model. A common model specification for the randomised complete block design (RCBD) is to include cultivar as a fixed effect and block as a random effect. Here is the R code for RCBD analsysis of the NIN data set loaded in Section 3 ?? that was found to have strong spatial correlation: library(nlme) nin.lme &lt;- lme(yield ~ gen, random = ~1|rep, data = Nin, na.action = na.exclude) anova(nin.lme) ## numDF denDF F-value p-value ## (Intercept) 1 165 242.05402 &lt;.0001 ## gen 55 165 0.87549 0.7119 library(spdep) xy.rook &lt;- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type=&quot;rook&quot;) moran.test(residuals(nin.lme), nb2listw(xy.rook), na.action = na.exclude) ## ## Moran I test under randomisation ## ## data: residuals(nin.lme) ## weights: nb2listw(xy.rook) ## omitted: 1, 12, 23, 34, 45, 56, 59, 67, 78, 89, 100, 108, 111, 122, 133, 144, 155, 204 ## ## Moran I statistic standard deviate = 8.1602, p-value &lt; 2.2e-16 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## 0.402504491 -0.004484305 0.002487522 The variables “gen” refers to the cultivar or breeding line being trialled, and “rep” is the block, and the dependent variable, “yield” is grain yield. Basic exploratory analysis was conducted in Section 3 ??. 5.2 Correlated Errors I: spatial distance Gaussian Example In order to fit models using correlated error model, we will need to first obtain preliminary estimates of the nugget, sill and range: from fitting an empirical variogram. library(gstat) max_dist &lt;- 0.6*max(dist(coordinates(Nin.spatial))) resid.var1 &lt;- variogram(yield ~ rep + gen, cutoff = max_dist, width = max_dist/29, data = Nin.spatial) nugget_start &lt;- min(resid.var1$gamma) Nin.vgm1 &lt;- vgm(model = &quot;Exp&quot;, nugget = nugget_start) Nin.vgm2 &lt;- vgm(model = &quot;Sph&quot;, nugget = nugget_start) Nin.vgm4 &lt;- vgm(model = &quot;Mat&quot;, nugget = nugget_start) Nin.variofit1 &lt;- fit.variogram(resid.var1, Nin.vgm1) Nin.variofit2 &lt;- fit.variogram(resid.var1, Nin.vgm2) Nin.variofit4 &lt;- fit.variogram(resid.var1, Nin.vgm4) In the previous section, an isotropic Gaussian function was identified as the best mocel for describing the decay of eror correlation over distance. Nin.vgm &lt;- vgm(model = &quot;Gau&quot;, nugget = nugget_start) Nin.variofit &lt;- fit.variogram(resid.var1, Nin.vgm) nugget &lt;- Nin.variofit$psill[1] range &lt;- Nin.variofit$range[2] sill &lt;- sum(Nin.variofit$psill) nugget.effect &lt;- nugget/sill Next, create a correlated error structure (from the nlme package). cor.gaus &lt;- corSpatial(value = c(range, nugget.effect), form = ~ row.length + col.width, nugget = T, fixed = F, type = &quot;gaussian&quot;, metric = &quot;euclidean&quot;) Last, update the linear mixed model with the correlated error strucutre and inspect the results: nin.gaus &lt;- update(nin.lme, corr = cor.gaus) anova(nin.gaus) ## numDF denDF F-value p-value ## (Intercept) 1 165 157.36740 &lt;.0001 ## gen 55 165 1.78151 0.0028 #moran.test(residuals(nin.gaus), nb2listw(xy.rook), na.action = na.exclude) Other models can be implemented quite similarily: 5.2.1 Exponential rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect) Nin.vgm &lt;- vgm(model = &quot;Exp&quot;, nugget = nugget_start) Nin.variofit &lt;- fit.variogram(resid.var1, Nin.vgm) nugget &lt;- Nin.variofit$psill[1] range &lt;- Nin.variofit$range[2] sill &lt;- sum(Nin.variofit$psill) nugget.effect &lt;- nugget/sill cor.exp &lt;- corSpatial(value = c(range, nugget.effect), form = ~ row.length + col.width, nugget = T, fixed = F, type = &quot;exponential&quot;, metric = &quot;euclidean&quot;) nin.exp &lt;- update(nin.lme, corr = cor.exp) anova(nin.exp) ## numDF denDF F-value p-value ## (Intercept) 1 165 62.35102 &lt;.0001 ## gen 55 165 1.83489 0.0018 5.2.2 Spherical rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect) Nin.vgm &lt;- vgm(model = &quot;Sph&quot;, nugget = nugget_start) Nin.variofit &lt;- fit.variogram(resid.var1, Nin.vgm) nugget &lt;- Nin.variofit$psill[1] range &lt;- Nin.variofit$range[2] sill &lt;- sum(Nin.variofit$psill) nugget.effect &lt;- nugget/sill cor.sph &lt;- corSpatial(value = c(range, nugget.effect), form = ~ row.length + col.width, nugget = T, fixed = F, type = &quot;spherical&quot;, metric = &quot;euclidean&quot;) nin.sph &lt;- update(nin.lme, corr = cor.sph) anova(nin.sph) ## numDF denDF F-value p-value ## (Intercept) 1 165 121.43563 &lt;.0001 ## gen 55 165 1.83709 0.0018 5.2.3 Power rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect) cor.pow &lt;- corSpatial(form = ~ row.length + col.width, nugget = T, fixed = F, type = &quot;ratio&quot;, metric = &quot;euclidean&quot;) nin.pow &lt;- update(nin.lme, corr = cor.pow) anova(nin.pow) ## numDF denDF F-value p-value ## (Intercept) 1 165 78.54890 &lt;.0001 ## gen 55 165 1.78787 0.0027 In the **nlme* package, there is also an option for a linear model in the corSpatial() function. However, it is recommended that a linear trend be fitted to the data instead. The package **spaMM* implements additional correlation models such as Matérn, Cauchy and more. 5.3 Nearest Neighbor Approaches 5.3.1 estimating lagged autocorrelation Prior to running any nearest neighbor appraoches, it is helpful to understand the lagged spatial autocorrelation. 5.3.2 Durban ?? 5.3.3 Spatial lag model library(spatialreg) nin.lag &lt;- lagsarlm(yield ~ gen + rep, listw = nb2listw(xy.rook), data = Nin, na.action = na.exclude) moran.mc(residuals(nin.lag), nb2listw(xy.rook), 999, na.action = na.exclude) ## ## Monte-Carlo simulation of Moran I ## ## data: residuals(nin.lag) ## weights: nb2listw(xy.rook) ## omitted: 1, 12, 23, 34, 45, 56, 59, 67, 78, 89, 100, 108, 111, 122, 133, 144, 155, 204 ## number of simulations + 1: 1000 ## ## statistic = -0.080738, observed rank = 67, p-value = 0.933 ## alternative hypothesis: greater 5.3.4 Spatial error model nin.sem &lt;- errorsarlm(yield ~ gen + rep, listw = nb2listw(xy.rook), data = Nin, na.action = na.exclude) moran.mc(residuals(nin.sem), nb2listw(xy.rook), 999, na.action = na.exclude) ## ## Monte-Carlo simulation of Moran I ## ## data: residuals(nin.sem) ## weights: nb2listw(xy.rook) ## omitted: 1, 12, 23, 34, 45, 56, 59, 67, 78, 89, 100, 108, 111, 122, 133, 144, 155, 204 ## number of simulations + 1: 1000 ## ## statistic = -0.1144, observed rank = 11, p-value = 0.989 ## alternative hypothesis: greater 5.3.5 Combined spatial lag and error model (ARMA) nin.arma &lt;- sacsarlm(yield ~ gen + rep, listw = nb2listw(xy.rook), data = Nin, na.action = na.exclude) moran.mc(residuals(nin.arma), nb2listw(xy.rook), 999, na.action = na.exclude) ## ## Monte-Carlo simulation of Moran I ## ## data: residuals(nin.arma) ## weights: nb2listw(xy.rook) ## omitted: 1, 12, 23, 34, 45, 56, 59, 67, 78, 89, 100, 108, 111, 122, 133, 144, 155, 204 ## number of simulations + 1: 1000 ## ## statistic = -0.036476, observed rank = 256, p-value = 0.744 ## alternative hypothesis: greater 5.4 p-Splines 5.4.1 AR1xAR1 (not possible!!) "],
["ch3-part3.html", "Section 6 Comparing Spatial Models 6.1 Example one 6.2 Example two", " Section 6 Comparing Spatial Models 6.1 Example one 6.2 Example two "],
["references.html", "References", " References "]
]
