--- 
title: "Incorporating Spatial Analysis into Agricultural Field Experiments."
author:
  - Julia Piaskowski^[University of Idaho, jpiaskowski@uidaho.edu]
  - William Price^[University of Idaho, bprice@uidaho.edu]
date: "`r format(Sys.Date(), '%B %d, %Y')`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib, extra.bib]
biblio-style: apalike
link-citations: yes
description: "Instructions for identifying spatial autocorrelation in agricultural field trials and incorporating spatial variation into analysis of trial using R and SAS."
github-repo: IdahoAgStats/guide-to-field-trial-spatial-analysis
---

# Preface

```{r, echo=FALSE,out.width="90%",fig.align='center'}
#knitr::include_graphics("img/road-auvers-after-rain-6_2840.jpg")
knitr::include_graphics("img/wheat_field_van_gogh.jpg")
```
<center>

Vincent Van Gogh

</center>

## Tutorial goal

*To help people conducting planned agricultural field trials understand and incorporate spatial variation routinely into analysis of field trials.*

Current educational resources are focused largely on geospatial applications that typically require a a moderate to deep understanding of  mapping tools and spatial analytic techniques. Furthermore, there is not a comprehensive resources for spatial analytic techniques for field experiments that is also freely available. This tutorial is intended to fill that gap. 

## Prerequisites

In order to run the scripts in this demonstration, you will to download R, available free through the [Comprehensive R Archive Network](https://cran.r-project.org/) (CRAN). While this is sufficient for running R scripts, You may also find it helpful to use RStudio, which provides a nice graphical user interface for R. RStudio can be downloaded [here](https://www.rstudio.com/products/rstudio/download/).

If you already have R installed, please make sure you have version 4.0.0 or newer. 

This demonstration is not intended to provide instructions on general R usage. However, There are numerous web resources for learning the Basics of R. [Software carpentry](https://software-carpentry.org/lessons/) offers several lesson plans covering the foundation of R.  

## R requirements

This tutorial was built using R version 4.1 ("Camp Pontanezen"). R session information is provided in section \@ref(the-end). 

**R Packages used in this tutorial**  

|Package |Usage in This Tutorial |
|------------|---------------|
|dplyr, tidyr, purrr | basic data manipulation | 
|ggplot, desplot | plotting | 
|agridat | contains demonstration data sets |
| sp, sf | standard manipulation of spatial objects | 
|spdep | spatial dependence functions | 
|gstat | empirical variogram estimation | 
|nlme, lme4 | mixed model analysis | 
|emmeans| extract treatments means |
| spaMM | Matérn covariance structure |
|SpATS | spatial splines for field trials |
|breedR | mixed modelling with AR1xAR1 estimation |

All packages aside from **breedR** are available on CRAN. The package **breedR**, is available on GitHub can be installed within R with the following code:

```
remotes::install_github("famuvie/breedR")
```

## SAS requirements

In order to run the SAS portion of this tutorial, a valid copy of SAS Base and Stat products and a current SAS license are required. This tutorial was built using SAS 9.4 (TS1M5). Although older versions of SAS may also work, we have not evaluated this. Users can also consider downloading and using a free version of [SAS® On Demand for Academics: Studio](https://www.sas.com/en_us/software/on-demand-for-academics/references/getting-started-with-sas-ondemand-for-academics-studio.html). 

**SAS procedures used in this tutorial**  

|Procedure |Usage in This Tutorial |
|------------|---------------|
|FORMAT, DATA, PRINT | basic data input, manipulation, and display | 
|SORT, RANK| sort and rank estimated means | 
|SGPLOT| plotting | 
|MIXED, GLIMMIX| mixed model analysis | 
|VARIOGRAM| empirical variogram estimation | 


## Contributors

[Julia Piaskowski](mailto:jpiaskowski@uidaho.edu) wrote the R sections and William Price wrote the SAS portions of this tutorial.

This book was written in [bookdown](https://bookdown.org/yihui/bookdown). 

## License

Incorporating Spatial Analysis into Agricultural Field Experiments by Julia Piaskowski and William Price is licensed under a [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-nc/4.0/)

```{r, echo=FALSE,out.width="20%",fig.align='center'}
knitr::include_graphics(c("img/CC-by-nc.png"))
```


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'tidyr', 'rmarkdown', 'gstat', 'sf',
  'dplyr','ggplot2', 'purrr', 'nlme', 'lme4', 'emmeans','spaMM', 'sp', 'spdep', 'spreg',
  'INLA', 'breedR', 'agridat', 'desplot', 'SpATS', 'psych'), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# Introduction {#intro}

## Why care about spatial variation?

The goal of many agricultural field trials is to provide information about crop response to a set a treatments such as soil treatments, disease pressure or crop genetic variation. Agricultural field trials employ common experimental designs such as randomized complete block design to account for environmental heterogeneity. However, those techniques are quite often inadequate to fully account for spatial heterogeneity that arises due to field position, soil conditions, disease, wildlife impacts and more. 

```{r echo=FALSE, out.width='90%', fig.align='center'}
knitr::include_graphics('img/plant_sciences_farm.PNG')
```
<center>
 
*University Research Farm*

</center>

When spatial autocorrelation is not accounted for in an analysis, the result can be incorrect treatment estimates, correlated errors (that violate the assumption of linear models and invalidate the analysis) and low experimental power. Incorporating spatial correlation between experimental plots can improve the overall accuracy and precision of these estimates. 

## Diagnosing spatial auto-correlation

Spatial correlation is similarity of plots that are close to one another.  That correlation is expected to decline with distance. This is different from experiment-wide gradients, such as a salinity gradient or position on a slope. 

### Moran's I

Moran's I, sometimes called "Global Moran's I" is similar to a correlation coefficient. It is a test for correlation between units (plots in our case). 

$$ I = \frac{N}{W}\frac{\sum_i \sum_j w_{ij} (x_i - \bar{x})(x_j - \bar{x})}{\sum_i(x_i - \bar{x})^2} 
\qquad i \neq j$$
and $j$, x is the variable of interest, $w_{ij}$ are a spatial weights between each $i$ and $j$, and W is the sum of all weights. The expected values of Moran's I is $-1/(N-1)$. Values greater than that indicate positive spatial correlation (areas close to each other are similar), while values less than the expected Moran's I indicate dissimilarity as spatial distance between points decreases. 
Where N is total number of spatial locations indexed by $i$ 

There are several options for defining adjacent neighbors and how to weight each neighbor's influence. The two common configurations for defining neighbors are the rook and queen configurations. These are exactly what their chess analogy suggests: "rook" defines neighbors in an row/column fashion, while "queen" defines neighbors in a row/column configuration an also neighbors located diagonally at a 45 degree angle from the row/column neighbors. Determining this can be somewhat complicated when working with irregularly-placed data (e.g. county seats), but is quite unambiguous for lattice data common in planned field experiments:

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)

na <- "Not adjacent"
o <- "Observation of interest"
n <- "Adjacent neighbor"

sp.config <- data.frame(row = rep(rep(1:5, 5), 2),
                        column = rep(rep(1:5, each = 5),2),
                        categ = c(rep(na, 5), #rook 
                                 na, na, n, na, na,
                                 na, n, o, n, na,
                                 na, na, n, na, na,
                                 rep(na, 5),
                                 rep(na, 5),  # start queen
                                 na, n, n, n, na,
                                 na, n, o, n, na,
                                 na, n, n, n, na,
                                 rep(na, 5)),
                        config = rep(c("rook", "queen"), each = 25) )

sp.config$categ <- factor(sp.config$categ, levels = c(o, n, na))

ggplot(sp.config, aes(x = row, y = column)) +
  geom_tile(aes(fill = categ), col = "black") +
  scale_fill_manual(values = c("red", "yellow", "white")) +
  facet_grid(. ~ config ) +
  theme_void() +
  coord_fixed() +
  theme(legend.title = element_blank(), 
        strip.text = element_text(size = 14),
        legend.text = element_text(size = 13))
 
```

Another test for diagnosing spatial correlation is Geary's C:

$$ I = \frac{(N -1)}{2W}\frac{\sum_i \sum_j w_{ij} (x_i - x_j)^2}{\sum_i(x_i - \bar{x})^2} \qquad i \neq j$$

These terms have the same meaning in Moran's I. The expected value of Geary's C is 1. Values higher than 1 indicate positive spatial correlation and less than 1 indicate negative spatial correlation. 

### Empirical variogram & semivariance

An empirical variogram is a visual tool for understanding how error terms are related to each other over spatial distance. It relies on semivariance ($\gamma$), a statistic expressing variance as a function of pairwise distances between data points at points $i$ and $j$.   

$$\gamma(h) = \frac{1}{2|N(h)|}\sum_{N(h)}(x_i - x_j)^2$$

Semivariances are binned for distance intervals. The average values for semivariance and distance interval can be fit to correlated error models such a exponential, spherical, Gaussian and Matérn. How to do this is explored further in \@ref(background) of this guide. 

Three important concepts of an empirical variogram are *nugget*, *sill* and  *range* 

![Example Empirical Variogram](img/Sadoti2014_spherical.jpg)

* range = distance up to which is there is spatial correlation
* sill = uncorrelated variance of the variable of interest
* nugget = measurement error, or short-distance spatial variance and other unaccounted for variance

**2 other concepts:** 

* partial sill = sill - nugget
* nugget effect = the nugget/sill ratio, interpreted opposite of $r^2$

<!--chapter:end:02-intro.Rmd-->

# Spatial Models {#background}

This section contains some of the statistical background behind why spatial models are used and how they work. Understanding this section is not essential, but it is extremely helpful. This section relies on information introduced in \@ref(intro), so please make sure you have read that section if you are new to empirical variograms and spatial statistics.  

General linear statistical models are commonly modeled as thus:

$$Y_i = \beta_0 + X_i\beta_1 + \epsilon_i$$
$\beta_1$ is a slope describing the relationship between a continuous variable and the dependent variable, $Y_i$. If $X_i$ is a categorical variable, such as a crop variety, then there will be $p-1$ slopes estimated, where p is the number of unique treatments levels in $X$. 

The error terms, $\epsilon_i$ are assumed normally distributed with a mean of zero and a variance of $\sigma^2$ :

$$e_i ~\sim N(0, \sigma^2)$$
The error terms, or residuals, are assumed to be *identically* and *independently* distributed (sometimes abbreviated "iid"). This implies a constant variance of the error terms and zero covariance between residuals. 

If N = 3, the expanded model looks like this:  

$$\left[ {\begin{array}{ccc} Y_1\\ Y_2\\ Y_3 \end{array} } \right] = \beta_0 + 
\left[ {\begin{array}{ccc} X_1\\ X_2\\ X_3 \end{array}  } \right] \beta_1 +
\left[ {\begin{array}{ccc} \epsilon_1\\ \epsilon_2\\ \epsilon_3 \end{array}  } \right] $$


$$e_i ~\sim N \Bigg( 0, 
\left[ {\begin{array}{ccc} \sigma^2 & 0 & 0 \\ 0 & \sigma^2 & 0\\ 0 & 0 & \sigma^2\end{array}  } \right] \Bigg) $$

If spatial variation is present, the off-diagonals of the variance-covariance matrix are not zero - hence the error terms are not independently distributed. As a result, hypotheses test and parameter estimates from uncorrected linear models will provide erroneous results. 

## Correlated error models

### Distance-based correlation error models

There are mathematical tools for modelling how error terms are correlated with each other based on pairwise physical distance between observations. These models can be used to weight observations. Often, the data are assumed to be *isotropic*, where distance but not direction impacts the spatial error correlation.

There are several methods for estimating the semivariance as a direct function of distance.

#### Exponential

$$ \gamma (h)\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left [ 1-e^{-(\frac{h}{r})} \right] & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$ 

```{r Exp-CE-fig, echo=FALSE, fig.cap='Exponential Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill = 1.7
psill = sill - c0
range = 0.5
x <- seq(0,2, by = 0.01)
y <- c0 + psill*(1-exp(-1*x/range))


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range*3, lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext(expression('r'[p]), side = 1, at = range*3)
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

$3r = r_p$ is the "practical range", which is 95% of the true value for $C_1$. 


#### Gaussian
(a squared version of the exponential model)

$$ \gamma (h)\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left [ 1-e^{-(\frac{h}{r})^2} \right] & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$

```{r Gau-CE-fig, echo=FALSE, fig.cap='Gaussian Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill = 1.7
psill = sill - c0
range = 0.75
x <- seq(0,2, by = 0.01)
y <- c0 + psill*(1-exp(-1*(x/range)^2))


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range*sqrt(3), lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext(expression('r'[p]), side = 1, at = range*sqrt(3))
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

$\sqrt 3r = r_p$ is the "practical range", which is 95% of the true value for $C_1$. 

#### Spherical

$$ \gamma (h) = \left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left[ \frac{3h}{2r}-0.5\bigg( \frac{h}{r}\bigg)^3 \right] & 0 <h \leq r \\ 
C_0 + C_1 & h > r \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$

```{r Sph-CE-fig, echo=FALSE, fig.cap='Spherical Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill <- 1.7
psill <- sill - c0
range = 1.3
x <- seq(0,2, by = 0.01)
y <- ifelse(x <= range, c0 + psill*((3*x)/(2*range) - 0.5*(x/range)^3),
            sill)

plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range, lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext('r', side = 1, at = range)
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

#### Other correlated error distance models 

There are many more models - Matérn, Cauchy, Logistic - that may describe spatial correlation in a data set. 

There are two addition models that have no range or sill, the linear model and power model. If your data fits these, consider doing a trend analysis.

#### Linear

$$ \gamma (h)=\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1h & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = slope $$

```{r linear-CE-fig, echo=FALSE, fig.cap='Linear Error Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
plot(0, c0, xlim = c(0,2), ylim = c(0, 2), axes = F, ann = F)
lines(c(0, 2),c(c0, 1.7), xlim = c(0,2), ylim = c(0, 2), col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
points(0, c0, pch = 21, bg = "white")
mtext("h", at = 2, side = 1)
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
```

There is no sill or range in the linear model, so the variance will continue to increase as a function of distance. 

#### Power

$$ \gamma (h)=\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1h^\lambda & h > 0 \end{array} } \right. $$
where

$$ 0 \leq \lambda <\leq 2 \\ C_0 = nugget \\ C_1 = scaling \: factor $$
```{r power-CE-fig, echo=FALSE, fig.cap='Power Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
c1 <- 1
lambda <- 0.5
x <- seq(0,2, by = 0.01)
y <- c0 + c1*(x^lambda)


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)

```

When $\lambda = 1$, that is equivalent to the linear model. Example above is when $\lambda = 0.5$ (i.e. a square-root transformation) and $C_1 = 1$.  There is also no sill or range in the power model. 

#### Matérn

$$\gamma(h) = c_0 + c_1 \bigg( 1- \frac{1}{2^{\kappa -1}\Gamma(\kappa)}
\Big( \frac{h}{\alpha} \Big) ^{\kappa} K_\kappa
\Big( \frac{h}{\alpha} \Big) \bigg)$$


Where

$$ C_0 = nugget \\ C_1 = partial \: scale \\ 
\alpha = smoothing \: factor \\ \kappa = covariance \: parameter
$$

$\Gamma(\kappa)$ is the gamma function:

$$\Gamma(\kappa) = (\kappa -1)!$$

and $\kappa(\alpha)$ is a modified bessel function: 

$$ K_\kappa(t) = \frac{\Gamma(\alpha)}{2} \big( \frac{t}{2} \big) ^{-\kappa}$$

```{r eval=FALSE, include=FALSE}
c0 <- 0.5
c1 <- 1.7
alpha = 0.5
kappa = 2

x <- seq(0,2, by = 0.01)
y <- ifelse(x <= range, c0 + psill*((3*x)/(2*range) - 0.5*(x/range)^3),
            sill)

plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range, lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext('r', side = 1, at = range)
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

### Correlated error model for gridded data

Planned field experiments often have the advantage of being arranged in regular grid pattern that can be adequately described using Euclidean space. This simplifies aspects of understanding how error terms are related by distance since the data occur in evenly spaced increments. Furthermore, in many agricultural trials, there may be no interest in spatial interpolation between units. Some of the following models work with irregularly-spaced data, but the models below are simplified forms when the experimental units are arranged in regular grid.

For example, imagine an experiment consisting of 8 plots (plot = the experiment units) arranged in 2 rows, each with 4 ranges with this layout: 

```{r plot-grid-fig, echo=FALSE, fig.asp=0.35, message=FALSE, warning=FALSE}
# plot(1, col = "white", xlim = c(0,4), ylim = c(0,2), ann = F, xaxt = "n", yaxt = "n") # xlab = "row", ylab = "ranges")
# grid(6, 10, lty = 1, col = "black")
# mtext("ranges", side = 2, at = 1.5)
# mtext("rows", side = 1, at = 2)

library(ggplot2)

dt <- data.frame(plot = paste0("plot ",1:8), row = rep(1:2, each = 4), range = rep(1:4, 2))

ggplot(dt, aes(x = range, y = row)) +
  geom_tile(col = "black", fill = "white") +
  geom_text(aes(label = plot)) +
  scale_y_continuous(breaks = c(1, 2)) +
  theme_classic() 
```

The statistical model for that experiment:

$$ 
\left[ {\begin{array} \ Y_1 \\ Y_2 \\ \vdots \\ Y_n \end{array} } \right] = \beta_0 + 
\left[ {\begin{array} \ X_1 \\ X_2 \\ \vdots \\ X_n \end{array} } \right] \beta_1 +
\left[ {\begin{array} \ \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_n \end{array} } \right]
$$
$X\beta$ refer to independent variable effects. This same model is also often presented in an abbreviated matrix form: 

$$ \mathbf{Y = X\beta + \epsilon}$$

#### First order auto-regressive model (AR1)

This assumes that variance can be modelled as exponential function based on unit distance (e.g. row or range), either in a single direction or anistropic. 

The AR1 structure across 2 rows is modeled as thus: 

$$\mathbf { V_{AR(1)row}}  = \sigma^2
\left[ {\begin{array}{cc} 
1 & \rho \\
\rho & 1 
\end{array} } \right] \otimes \mathbf{I_4}$$

This covariance model describes the correlation of observations in the *row direction only.* 

And similarly the AR1 structure across 4 ranges is modeled as thus: 

$$ \mathbf {V_{AR(1)range}} = \sigma^2 \mathbf{I_4} 
\left[ {\begin{array}{cccc} 
1 & \rho & \rho^2 & \rho^3 \\
\rho & 1 & \rho & \rho^2  \\
\rho^2 & \rho & 1 & \rho  \\
\rho^3 & \rho^2 & \rho & 1
\end{array} } \right] \otimes \mathbf{I_2} $$

This covariance model describes the correlation of observations in the *range direction only.* 

In combined AR1xAR1 model, the parameter, $\rho$ may need to estimated separated across the row and column directions depending on the shape of the plots and site-specific field variation. Very rectangular plots are likely to require a separate estimate of the $\rho$ parameter for each direction. 

\begin{equation}
\mathbf {V_{AR(1)row} \otimes V_{AR(1)range}} = \sigma^2
\left[ {\begin{array}{cccc | cccc} 

1 & \rho_1 & \rho_1^2 & \rho_1^3 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1^3\rho_2 \\
\rho_1 & 1 & \rho_1 & \rho_1^2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2\\
\rho_1^2 & \rho_1 & 1 & \rho_1 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2\\
\rho_1^3 & \rho_1^2 & \rho_1 & 1 & \rho_1^3\rho_2 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 \\
\hline
\rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1^3\rho_2 & 1 & \rho_1 & \rho_1^2 & \rho_1^3 \\
\rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1 & 1 & \rho_1 & \rho_1^2 \\
\rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2 & \rho_1 & 1 & \rho_1 \\
\rho_1^3\rho_2 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 &\rho_1^3 & \rho_1^2 & \rho_1 & 1 \\

\end{array} } \right]
\end{equation}


**Note**: $\rho_1$ and  $\rho_2$ are the parameter estimate for $V_{AR1(1) row}$ and $V_{AR(1)range}$, respectively.

Please note that these error models are for modelling localised variation based on physical proximity. It is assumed that eventually a distance in the experiment can be reached in which 2 observations can be treated independent. 

If there are spatial trends that extend along the entire scope of an experiment (for instance, due to position on a slope), then an additional trend analysis should be conducted.

## Spatial Regression methods

These approaches look use information from adjacent plots to adjust for spatial auto-correlation. 

### Spatial autoregressive (SAR)

Sometimes called a "lag" model, the SAR model uses correlations with neighboring plots dependent variable to predict Y. The auto-regressive model explicitly models correlations between neighboring points. 

$$\mathbf{Y =  \rho W Y + X\beta + \epsilon} $$

While this may look strange, $\mathbf{W}$ is an $n$ x $n$ matrix weighting the neighbors with a diagonal of zero so the value at $i=j$, that is $Y_{ijk}$ itself, is not used on the right-hand side to predict $Y_{ijk}$ on the left-hand side of the equation. The error terms are assumed iid. 

**On Weights**

Setting weights of neighbors is dealt with in the next chapter \@ref(rcbd-r). 

## Trend analysis

### Row and column trends

Experiment wide-trends should be modeled with directional trend models. These are comparatively simple models:

$$Y_{ijk} = \beta_0 + X_{i1}\beta_1 +  Row_{j2}\beta_2 + Range_{k3}\beta_3 +\epsilon_{ijk}$$ 

If the assumption of independent, normal, and identical errors are met, then this model will suffice. If spatial variation is still present, additional measures will need to be taken. 

### Splines

There is a rich field of research on using localised splines to model field heterogeneity. They are similar to trend models where the row and/or column trends are modelled. These models are complex and hence not described here.  

<!--chapter:end:03-background.Rmd-->

# Identifying Spatial Variation: R {#spatial-r}

## Load data

This tutorial uses the Nebraska Interstate wheat trials, first published by Stroup et al in 1994 [@stroup1994] and reused extensively in field spatial variation studies. 

```{r message=FALSE, warning=FALSE}
library(agridat); library(dplyr); library(tidyr)

data("stroup.nin")

Nin <- stroup.nin %>% mutate(col.width = col * 1.2, 
                             row.length = row * 4.3) %>% 
  mutate(name = case_when(is.na(as.character(rep)) ~ NA_character_, 
                          TRUE ~ as.character(gen))) %>% 
  arrange(col, row)

Nin_na <- filter(Nin, !is.na(rep))
```

### Examine data

```{r}
head(Nin)
```

This data set actually has no missing data -- this is a balanced trial. However, there are empty fill plot with no data which creates some issues regarding NA handling. 

Plot raw yield data as it appeared in the field: 
```{r message=FALSE, warning=FALSE}
library(ggplot2); library(desplot)
```

```{r Nin-yield-layout-fig, out.width="100%",fig.asp=.7,message=FALSE, warning=FALSE}
ggplot(Nin, aes(x = row, y = col)) +
  geom_tile(aes(fill = yield), col = "white") +
  #geom_text(aes(label = name)) +
  geom_tileborder(aes(group = 1, grp = rep), lwd = 1.2) +
  scale_fill_gradient(low = "white", high = "blue") +
  scale_x_continuous(breaks = seq(1,max(Nin$row), 1)) +
  scale_y_continuous(breaks = 1:max(Nin$col)) +
  labs(x = "row", y = "column", title = "field plot layout") + 
  theme_classic() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12))
```

Black lines delineate the blocks. 

It's also helpful to plot raw response data: 
```{r Nin-boxplot-fig, out.width="80%",fig.asp = .6}
par(mfrow=c(1,3))
boxplot(yield ~ rep, data = Nin, xlab = "rep", ylab = "yield (bu/acres)", col = "red2", main = "yield across blocks")
boxplot(yield ~ row, data = Nin, xlab = "row", ylab = "yield (bu/acres)",col = "dodgerblue2", main = "yield across rows")
boxplot(yield ~ col, data = Nin, col = "gold", xlab = "column", ylab = "yield (bu/acres)",main = "yield across columns")
par(mfrow=c(1,1))
```

## Test for spatial autocorrelation

### Moran's I

First, run a standard linear model of the experiment: 
```{r message=FALSE, warning=FALSE}
library(nlme)

nin.lme <- lme(yield ~ gen, random = ~1|rep,
              data = Nin,
              na.action = na.exclude)
```

Next, establish and weight neighbors for each plot. In this example, only adjacent neighbors in the rook formation (see \@ref(background)) are used and are weighted proportionally according to their representation as neighbors to an individual. That is, if a unit has 4 adjacent neighbors, each neighbor is weighted as 0.25. If there are only two neighbors, each is weighted 0.5. 

The function `cell2nb()` is a function for setting neighbors when working with data laid out in a regular grid. 

```{r message=FALSE, warning=FALSE}
library(spdep)
xy_rook <- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type="rook", torus = FALSE, legacy = FALSE)  
```

**Make sure your data sorted by the variables assigned to row and col (in that order), and there is one and only one observation in the data set for each unique row/col combination. Even missing plots need a row.**

*Rook adjacency plot for the NIN data*
```{r nin-rook-adj-fg, message=FALSE, warning=FALSE, fig.cap='Rook adjacency plot for the NIN data'}
library(sf)
rook_matrix <- st_as_sf(expand.grid(col=1:22, row=1:11), coords=c("col", "row"))
plot(xy_rook, coords = st_geometry(rook_matrix), points = TRUE)
```
Each observation considers "neighbors" to be those which touch the cell in a row or column orientation, but not diagonal. 

Conduct Moran's test via standard t-test and using MC sampling. 
```{r}
resid_lme <- residuals(nin.lme)
names(resid_lme) <- Nin$plot
moran.test(resid_lme, nb2listw(xy_rook), na.action = na.exclude)
moran.mc(resid_lme, nb2listw(xy_rook), 999, na.action = na.exclude)
```

Plot Spatial dependence of residuals

```{r resid-cor-fig, message=FALSE, warning=FALSE}
library(purrr)

res.nn1 <- map_dbl(xy_rook, function(j) mean(resid_lme[j]))
  
rc <- signif(cor(resid_lme, res.nn1, use = "pairwise.complete.obs"), 2)

plot(x = resid_lme, y = res.nn1, 
     main = paste0("r = ", rc), xlab = "residual", ylab = "average residual of neighbor (rook)")
```

### Note on Geary's C

At this time, the **spdep** function `geary.test()` for Geary's C does not handle missing spatial points. It cannot be used it for the NIN data set because it contains empty plots between each block with no data available for those plots. 
 
## Empirical variogram fitting

First, create a spatial object by adding spatial coordinates to an ordinary data frame. I like to use the actual size of the plots since they are often exaggerated rectangles that have a significantly greater length than width.

```{r}
library(sp)
Nin_spatial <- Nin_na
coordinates(Nin_spatial) <- ~ col.width + row.length
class(Nin_spatial)
```

Set the maximum distance for calculating the variogram model (which is one-half the maximum distance between two points).

```{r}
max_dist = 0.6*max(dist(coordinates(Nin_spatial)))
round(max_dist, digits = 2)
``` 

Calculate semivariance for an isotropic model and plot the variogram. 

```{r possible-error}
library(gstat)
class(Nin_spatial)
head(Nin_spatial)
resid_var1 <- gstat::variogram(yield ~ rep + gen, 
                        cutoff = max_dist,
                        width = max_dist/20, # 20 is the number of bins
                        data = Nin_spatial)
plot(resid_var1)
```

Test out correlated error models:

First, set the starting nugget values as the minimum of the semi-variance. There is likely more sophisticated methods to establish the starting value for nugget, but I have found that extracting the minimum value of the semivariance to work well as a starting point. 

```{r}
nugget_start <- min(resid_var1$gamma)
```

Establish models for variogram fitting. 
```{r}
Nin_vgm1 <- vgm(model = "Exp", nugget = nugget_start) # exponential
Nin_vgm2 <- vgm(model = "Sph", nugget = nugget_start) # spherical
Nin_vgm3 <- vgm(model = "Gau", nugget = nugget_start) # Gaussian
Nin_vgm4 <- vgm(model = "Mat", nugget = nugget_start) # Matern
```

Fit the variograms to the data:
```{r message=FALSE, warning=FALSE}
Nin_variofit1 <- fit.variogram(resid_var1, Nin_vgm1)
Nin_variofit2 <- fit.variogram(resid_var1, Nin_vgm2)
Nin_variofit3 <- fit.variogram(resid_var1, Nin_vgm3)
Nin_variofit4 <- fit.variogram(resid_var1, Nin_vgm4, fit.kappa = T)
```

### Compare variograms

Look at the results! (this is fun)

```{r}

plot(resid_var1, Nin_variofit1, main = "Exponential model")
plot(resid_var1, Nin_variofit2, main = "Spherical model")
plot(resid_var1, Nin_variofit3, main = "Gaussian model")
plot(resid_var1, Nin_variofit4, main = "Matern model")
```

How to pick the best one model? The attribute "SSError" indicates how well each model was able to predict the binned error terms as a function of distance. However, it's important to look at the model as well to see if the model was able to fit the data.  

```{r}
print("Exponential"); attr(Nin_variofit1, "SSErr")
print("Spherical"); attr(Nin_variofit2, "SSErr")
print("Gaussian"); attr(Nin_variofit3, "SSErr")
print("Matern"); attr(Nin_variofit4, "SSErr")
```

`Nin_variofit3` had the lowest error terms, corresponding to the Gaussian model.

Results from the empirical variogram:

```{r}
Nin_variofit3
```

The variogram parameters can be easily extracted from this table:

```{r}
nugget <- Nin_variofit3$psill[1] # "measurement error"
range <- Nin_variofit3$range[2] # distance to establish independence between data points
sill <- sum(Nin_variofit3$psill) # maximum semivariance
```

### Explore anisotropy

Most field experiments occur on a relatively small scale,where the entire experimental layout is less than 0.25 square miles. As such, isotropic models (where spatial correlation is based on distance but not direction) are often adequate for understanding localised field heterogeneity. However, there are always exceptions where a spatial correlation in a field trail is best describe by an anistropic model.  

Reestablish models for variogram fitting: 
```{r}
Nin_vgm1a <- vgm(model = "Exp", anis = c(90, 0.5)) # 90 refers to the angle of the main direction and 0.5 creates a second 90 degree axis of variability to estimate 
Nin_vgm2a <- vgm(model = "Sph", anis = c(90, 0.5))
Nin_vgm3a <- vgm(model = "Gau", anis = c(90, 0.5))
Nin_vgm4a <- vgm(model = "Mat", anis = c(90, 0.5))
```

Fit the variograms to the data:
```{r message=FALSE, warning=FALSE, error=TRUE}
Nin_variofit1a <- fit.variogram(resid_var1, Nin_vgm1a)
Nin_variofit2a <- fit.variogram(resid_var1, Nin_vgm2a)
Nin_variofit3a <- fit.variogram(resid_var1, Nin_vgm3a)
Nin_variofit4a <- fit.variogram(resid_var1, Nin_vgm4a, fit.kappa = T)
```

Look at rums of squares error: 

* Exponential 
```{r}
attr(Nin_variofit1a, "SSErr")
```

* Spherical
```{r}
attr(Nin_variofit2a, "SSErr")
```

* Gaussian
```{r}
attr(Nin_variofit3a, "SSErr")
```

* Matérn
```{r}
attr(Nin_variofit4a, "SSErr")
```

These error terms are considerably higher than in the isotropic model.

```{r}
plot(resid_var1, Nin_variofit1a, main = "Exponential model")
```

Hmm, that plot is not very convincing. 

In this field trial, there is evidence of spatial correlation as a function of distance, but there is not evidence this spatial correlation is impacted by direction.

**Another reminder on field trends**  

It's important to remember these methods are intended to describe localised spatial correlation. Field-wide spatial gradients, such as position on a slope, should be modelled as a separate trend. 

<!--chapter:end:04-spatial-diagnostic-R.Rmd-->

# RCBD Example: R {#rcbd-r}

Here are step-by-step instructions for how to incorporate spatial covariates into analysis of a field experiment that uses a randomized complete block design. Several techniques are explored: 

Load the NIN data if it is not already in your R environment: 

```{r message=FALSE, warning=FALSE}
library(agridat); library(dplyr); library(tidyr); library(purrr);
library(sp)
```

```{r error-chunk}
data("stroup.nin")

Nin <- stroup.nin %>% mutate(col.width = col * 1.2, 
                             row.length = row * 4.3) %>% 
  fill(rep, .direction = "up") %>%  arrange(col, row) 

Nin_na <- filter(Nin, !is.na(yield))
Nin_spatial = Nin_na
coordinates(Nin_spatial) <- ~ col.width + row.length
```

Once spatial auto-correlation has been identified in field trials, the next step is to employ a modeling technique that will reduce the impact of spatial variation on the final estimates from the analysis.  

## Prep work

The first thing is to run a standard linear model. A common model specification for the randomized complete block design (RCBD) is to include cultivar as a fixed effect and block as a random effect. 

```{r message=FALSE, warning=FALSE}
library(nlme); library(emmeans)

nin_lme <- lme(yield ~ gen, random = ~1|rep,
              data = Nin,
              na.action = na.exclude)

# extract the least squares means for variety
preds_lme <- as.data.frame(emmeans(nin_lme, "gen"))
```

The variables "gen" refers to the cultivar or breeding line being trialled, and "rep" is the block, and the dependent variable, "yield" is grain yield. Basic exploratory analysis of this data set was conducted in \@ref(spatial-r).

## Correlated errors 

**Gaussian Example**

In order to fit models using correlated error model, we will need to first obtain preliminary estimates of the nugget, sill and range: from fitting an empirical variogram. 

```{r}
library(gstat)
max_dist <- 0.6*max(dist(coordinates(Nin_spatial)))
resid.var1 <- gstat::variogram(yield ~ rep + gen, 
                        cutoff = max_dist,
                        width = max_dist/10, 
                        data = Nin_spatial)
nugget_start <- min(resid.var1$gamma)
``` 

In the previous section, an isotropic Gaussian function was identified as the best model for describing the decay of error correlations over distance.

```{r}
nin_vgm <- vgm(model = "Gau", nugget = nugget_start) 
nin_variofit <- fit.variogram(resid.var1, nin_vgm)

nugget <- nin_variofit$psill[1] 
range <- nin_variofit$range[2] 
sill <- sum(nin_variofit$psill) 
nugget.effect <-  nugget/sill
```

Create a correlated error structure using the **nlme** package.
```{r}
cor.gaus <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "gaussian", 
                  metric = "euclidean")
```

Update the linear mixed model with the correlated error structure:
```{r}
nin_gaus <- update(nin_lme, corr = cor.gaus)
```

Extract variety estimates: 
```{r}
preds_gaus <- as.data.frame(emmeans(nin_gaus, "gen"))
```

Other models can be implemented following this template. 

### Exponential

```{r}
rm(nin_vgm, nin_variofit, nugget, sill, range, nugget.effect)

nin_vgm <- vgm(model = "Exp", nugget = nugget_start) 
nin_variofit <- fit.variogram(resid.var1, nin_vgm)

nugget <- nin_variofit$psill[1] 
range <- nin_variofit$range[2] 
sill <- sum(nin_variofit$psill) 
nugget.effect <-  nugget/sill

cor.exp <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "exponential", 
                  metric = "euclidean")

nin_exp <- update(nin_lme, corr = cor.exp)
preds_exp <- as.data.frame(emmeans(nin_exp, "gen"))
```

### Spherical

```{r}
rm(nin_vgm, nin_variofit, nugget, sill, range, nugget.effect)

nin_vgm <- vgm(model = "Sph", nugget = nugget_start) 
nin_variofit <- fit.variogram(resid.var1, nin_vgm)

nugget <- nin_variofit$psill[1] 
range <- nin_variofit$range[2] 
sill <- sum(nin_variofit$psill) 
nugget.effect <-  nugget/sill

cor.sph <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "spherical", 
                  metric = "euclidean")

nin_sph <- update(nin_lme, corr = cor.sph)
preds_sph <- as.data.frame(emmeans(nin_sph, "gen"))
```

### Matérn

A Matérn error function is not available in **nlme**, but the package **spaMM** has written an extension implementing the Matérn, Cauchy and other covariance structures. The Matérn is demonstrated below. 


```{r message=FALSE, warning=FALSE}
rm(nin_vgm, nin_variofit, nugget, sill, range, nugget.effect)

library(spaMM) # required for running `corMatern()`

nin_vgm <- vgm(model = "Mat", nugget = nugget_start) 
nin_variofit <- fit.variogram(resid.var1, nin_vgm, fit.kappa = TRUE)
 
nugget <- nin_variofit$psill[1] 
range <- nin_variofit$range[2] 
sill <- sum(nin_variofit$psill) 
nugget.effect <-  nugget/sill
kappa <- nin_variofit$kappa[2]

# from spAMM documentation: "Warning: the range parameter used in corSpatial objects is the inverse of the scale parameter used in MaternCorr and thus they have opposite meaning despite both being denoted ρ elsewhere in this package or in nlme literature" - so range is expressed as an inverse
cor.mat <- corMatern(value = c(1/range, kappa, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  metric = "euclidean")
nin_matern <- update(nin_lme, corr = cor.mat)

preds_mat <- as.data.frame(emmeans(nin_matern, "gen"))
```


In the **nlme** package, there is also an option for a linear model in the `corSpatial()` function. However, if a linear trend is present without a range or sill, it is recommended that a linear trend be fitted to the data instead. 

## Row/Column Trends: 

The package **lme4** is used since it can handle multiple random effects while **nlme** cannot do this without nesting the effects. I prefer **nlme** for linear modeling in this tutorial because of its built-in functionality for including spatial variation. 
```{r message=FALSE, warning=FALSE}
library(lme4); library(lmerTest)
```

```{r}
# variables specifying row and column as factors are needed
Nin$colF <- as.factor(Nin$col)
Nin$rowF <- as.factor(Nin$row)

nin_trend <- lmer(yield ~ gen + (1|rep) + (1|colF) + (1|rowF),
              data = Nin,
              na.action = na.exclude)

preds_trend <- as.data.frame(emmeans(nin_trend, "gen"))
```

## Splines

The package **SpATS**, "spatial analysis for field trials", implements B-splines for row and column effects. 
```{r message=FALSE, warning=FALSE}
library(SpATS)

nin_spline <- SpATS(response = "yield", 
                    spatial = ~ PSANOVA(col, row, nseg = c(10,20),
                                        degree = 3, pord = 2), 
                    genotype = "gen",  
                    random = ~ rep, # + rowF + colF, 
                    data = Nin, 
                    control = list(tolerance = 1e-03, monitoring = 0))

preds_spline <- predict(nin_spline, which = "gen") %>% 
  dplyr::select(gen, emmean = "predicted.values", SE = "standard.errors")
```

## AR1xAR1

```{r include=FALSE}
if(!require(breedR)) {
  #devtools::install_github('famuvie/breedR')
  source("http://famuvie.github.io/breedR/src/setup_repo.R")
  install.packages('breedR')
}
```


```{r message=FALSE, include=FALSE, echo=TRUE}
library(breedR); library(ggplot2)

nin_ar1ar1  <- remlf90(fixed  = yield ~ gen,
                       #random = ~ rep, # model would not converge with rep included
                       spatial = list(model = 'AR', 
                                  coord = Nin[, c('col','row')]), 
                       data = Nin)

```

The estimates for $\rho$ are determined via a grid search. The default grid searches the entire space, ([-1, 1] for rows and columns) We can narrow down the grid search to the area most impactful based on log likelihood. 
```{r}
qplot(rho_r, rho_c, fill = loglik, geom = 'tile', data = nin_ar1ar1$rho)

# Refine the grid around the most likely values (the range cannot contain exactly 1 or -1)
rho.grid <- expand.grid(rho_r = seq(0.5, 0.95, length = 4),
                        rho_c = seq(0.5, 0.95, length = 4))
```
```{r message=FALSE, include=FALSE, echo=TRUE}
nin_ar1ar1  <- remlf90(fixed  = yield ~ gen, 
                       #random = ~ rep, #this also did not converge
                       spatial = list(model = 'AR',
                                  coord = Nin[, c('col','row')],
                                  rho = rho.grid), 
                       data = Nin)

preds_ar1ar1 <- as.data.frame(fixef(nin_ar1ar1)[[1]]) %>% tibble::rownames_to_column("gen") %>% 
  mutate(SE = attr(fixef(nin_ar1ar1)[[1]], "se"))
colnames(preds_ar1ar1)[2] <- "emmean"
```


## Bayesian AR1xAR1

```{r}
#library(INLA) 
## under construction....
```

## Model Selection

Now that we have built these spatial models, how do we pick the right one? Unfortunately, there is no one model that works best in all circumstances. In addition, there is no single way for choosing the best model! Some approaches include:

1. comparing model fitness (e.g. AIC, BIC, log likelihood) 
1. comparing post-hoc power (that is, the p-values for the treatments)
1. comparing standard error of the estimates

In order to make comparisons, the code below assembles all the model objects into one list. They are generated from different processes, as shown by the `class` attribute of each one, so this takes some data conditioning.  

```{r include=FALSE, message=FALSE}
rm(nin_variofit, nin_vgm)
rm(nin_vgm, nin_variofit, nugget, sill, range, nugget.effect)
```


```{r message=FALSE, warning=FALSE}
all.models <- mget(ls(pattern = "^nin_*"))
# print out their class
map(all.models, class)
```

### Spatial dependence of residuals

It would be helpful to know if these methods were effective in reducing the spatial autocorrelation among the error residuals. 

The function below extracts the residuals from each model and is needed because of different handling of missing values by the package **SpATS**. 

```{r message=FALSE, warning=FALSE}
L1 <- nrow(Nin)
non_na <- !is.na(Nin$yield)
L2 <- sum(non_na)

residuals <- map(all.models, function (x) {
  
  resids <- residuals(x)
  
  if(is.data.frame(resids)) {
    colnum = ncol(resids)
    resids = resids[,colnum]
  }
  
  if(length(resids) == L2) {
    resids_pl = rep(NA, L1)
    resids_pl[non_na] = resids
    resids = resids_pl
  }
  return(resids)
})

names(residuals) <- names(all.models)
```

Run a Moran's I test on the extracted residuals:

```{r message=FALSE, warning=FALSE}
library(spdep)

xy.rook <- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type="rook")

Moran.I <- map_df(residuals, function(x) {
  mi = moran.test(x, nb2listw(xy.rook), na.action = na.exclude)
  mi.stat <- mi$estimate
  mi.stat$p.value <- mi$p.value
  return(mi.stat)
}) %>% mutate(model = names(all.models)) %>% dplyr::select(c(5, 1:4)) %>% 
  mutate_at(2:5, round, 4) %>% arrange(p.value)

Moran.I
```

Only one model, `nin_spline` resulted in an improvement in Moran's I. Nearest neighbor approaches can also improve Moran's I. The significant p-values indicate that auto-correlation is still present in those models. However, that doesn't mean the other models are ineffective. The other models incorporate the spatial auto-correlation directly into the error terms. 

### Compare Model Fit
*log likelihood, AIC, BIC*

Since these are not nested models, likelihood ratio tests cannot be performed. Log likelihood can be compared within the models from **nlme** but not across packages since they use different estimation procedures.

```{r}
nlme_mods <- list(nin_lme, nin_trend, nin_exp, nin_gaus, nin_sph, nin_matern, nin_ar1ar1)

names(nlme_mods) <- c("LMM", "row-col_trend", "exponential", 
                        "gaussian", "spherical", "matern", "AR1xAR1")

data.frame(logLiklihood = sapply(nlme_mods, logLik),
           AIC = sapply(nlme_mods, AIC),
           BIC = sapply(nlme_mods, AIC, k = log(nrow(Nin_na)))) %>% arrange(desc(logLiklihood))
```

Larger log likelihoods indicate a better fitting model to the data. A rule of thumb when comparing log likelihoods is that differences less than 2 are not considered notable. These results suggest that the Gaussian, spherical, power and Matérn models are substantially equivalent in capturing the variation present in this data set. 

### Experiment-wide error

```{r}
exp_error <- as.data.frame(sapply(nlme_mods[-7], sigma))
exp_error
```

The overall experimental error, $\sigma$, increased slightly in the correlated error models because field variation has been re-partitioned to the error when it was (erroneously) absorbed by the other experimental effects. 

As a result, the coefficient of variation is not a good metric for evaluating the quality of spatial models. 

```{r}
CV = sapply(nlme_mods[-7], function(x) {
  sigma(x)/mean(fitted(x), na.rm = T) * 100
})
as.data.frame(CV)
```

### Post-hoc power

Simulation studies indicate that incorporating spatial correlation into field trial analysis can improve the overall power of the experiment (the probability of detecting true differences in treatments). When working with data from a completed experiment, power is a transformed p-value. Performing ANOVA can indicate which approach maximizes power. 

```{r message=FALSE, warning=FALSE}
anovas <- lapply(nlme_mods[-7], function(x){ 
  aov <- as.data.frame(anova(x))[2,]
  })

a <- bind_rows(anovas) %>% mutate(model = c("LMM", "row/column trend", "exponential", 
                                       "gaussian", "spherical", "matern")) %>% 
  arrange(desc(`p-value`)) %>% dplyr::select(c(model, 1:4)) %>% tibble::remove_rownames() 

a[6,2:5] <- anova(nin_trend)[3:6]
a
```

This table indicates changes in the hypothesis test for "gen".  There is a dramatic change in power for this test when incorporating spatial covariance structures. 

### Standard error of treatment means

Retrieve predictions generated in the previous section:
```{r}
#(standardise names for downstream merging step)
#preds_ar1ar1 <- preds_ar1ar1  %>% rename(emmean = "predicted.value", SE = "standard.error") 
all.preds <- mget(ls(pattern = "^preds_*")) 
```

Extract standard errors and plot: 
```{r message=FALSE, warning=FALSE}
errors <- lapply(all.preds, "[", "SE")
pred.names <- gsub("preds_", "", names(errors))
error_df <- bind_cols(errors)
colnames(error_df) <- pred.names
```

```{r SE-box-fig, echo=FALSE, fig.cap='Differences in Variety Standard Error', out.width='80%', fig.asp=0.75, fig.align='center'}
boxplot(error_df, ylab = "standard errors", xlab = "linear model", col = "dodgerblue3")
```

### Treatment means

Extract estimates:
```{r message=FALSE, warning=FALSE}
preds <- lapply(all.preds, "[", "emmean")
preds_df <- bind_cols(preds)
colnames(preds_df) <- pred.names
preds_df$gen <- preds_exp$gen
```

Plot changes in ranks: 

```{r gen-ranks-fig, echo=FALSE, fig.align='center', fig.asp=0.75, fig.cap='Differences in Variety Ranks', message=FALSE, warning=FALSE, out.width='85%'}
library(ggplot2)

lev <- c("lme", "trend", "exp", "gaus", "mat", "sph", "ar1ar1", "spline")

#reshape::melt(preds_df, id.vars = "gen", variable.name = "model", value.name = "emmeans") %>% 
pivot_longer(preds_df, cols = !gen, names_to = "model", values_to = "emmeans") %>% 
  mutate(model = factor(model, levels = lev)) %>% 
  ggplot(aes(x = model, y = emmeans, group = gen)) +
  geom_point(size = 5, alpha = 0.5, col = "navy") +
  geom_line() +
  ylab("yield means for gen") + 
  theme_minimal(base_size = 14)
```

The black lines link the least squares means for a single variety. There is some consistency in the rankings between exponential, Gaussian, Matérn, and spherical covariance models. The control RCBD model, "lme", has fundamentally different rankings. The spline and AR1xAR1 ranking are also sightly different from the other models. 

Nevertheless, the following plot indicates considerable consensus in the least squares means from all of the spatial models. The upper diagonal contains Pearson correlations between those values. 

```{r ls-panel-fig, echo=FALSE, fig.align='center', fig.asp=1, fig.cap='Correlations in Variety Means', message=FALSE, warning=FALSE, out.width='90%'}
library(psych)
pairs.panels(preds_df[,-9], smooth = F, density = F, ellipses = F, 
             hist.col = "gold", pch = 1)
```


## Making decisions

There is no consensus on how to pick the best model. Some studies rely on log likelihood, while others seek to maximize the experimental power. Others have sought to minimize the root mean square error from cross validation.

The evidence suggest that for this data set, using any spatial model is better than running a naïve RCBD model.  

<!--chapter:end:05-rcbd-spatial-example-R.Rmd-->

# RCBD Example: SAS {#rcbd-sas}

```{r include=FALSE}
require(SASmarkdown)
saspath <- "C:/Program Files/SASHome/SASFoundation/9.4/sas.exe"
sasopts <- "-nosplash -ls 200"
```

## Load and Explore Data

These data are from a winter wheat variety trial in Alliance, Nebraska [@stroup1994] and are commonly used to demonstrate spatial adjustment in linear modeling. The data represent yields of 56 varieties originally laid out in a randomized complete block design (RCB). The local topography combined with winter kill, however, induced spatial variability that did not correspond to the RCB design [@stroup2013] which produced biased estimates in a standard unadjusted analysis. <br><br>

The code below reads the data from a CSV file located the GitHub repo for this book. The data file can be downloaded from [here](https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/stroup_nin_wheat.csv). In this file, missing values for yield are denoted as 'NA'. These values are not actually missing, but represent blank plots separating blocks in the original design of the study. The **PROC FORMAT** section converts these to numeric missing values in SAS (defined as a single period). They are then removed from the data before proceeding to analyses. Also note that row and column indices are multiplied by constants to convert them to the meter dimensions of the plots. . <br><br>

The first six observations are displayed. The data contains variables for variety (gen), replication (rep), yield, and column and row identifiers.<br><br> Last, a map of the 4 replications (blocks) from the original experimental design is shown.

```{r SAS6_1, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
proc format;
  invalue has_NA
  'NA' = .;
;

filename NIN url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/stroup_nin_wheat.csv";

data alliance;
    infile NIN firstobs=2 delimiter=',';
    informat yield has_NA.;
    input entry $   rep $   yield   col row;
    Row  = 4.3*Row;
    Col = 1.2*Col;
    if yield=. then delete;
run;

proc print data=alliance(obs=6);
title1 ' Alliance Nebraska Wheat Variety Data';

run;
ODS html GPATH = ".\img\" ;

proc sgplot data=alliance;
	styleattrs datacolors=(cx28D400 cx00D4C8 cx0055D4 cxB400D4) datalinepatterns=(solid dash);
	HEATMAPPARM y=row x=col COLORgroup=rep/ outline; 
title1 'Layout of Blocks';
run;
```

### Plots of Field Trends

A first step in assessing spatial variability is to plot the data to visually assess any trends or patterns. This code uses the **SGPLOT** procedure to examine spatial patterns through a heat map of yields, as well as potential trends across replications, columns, and rows using box plots.

```{r SAS6_2, engine="sashtml",  engine.path=saspath, engine.opts=sasopts, include=TRUE, comment=""}
ODS html GPATH = ".\img\" ;

proc sgplot data=alliance;
	HEATMAPPARM y=Row x=Col COLORRESPONSE=yield/ colormodel=(blue yellow green); 
run;

proc sgplot data=alliance;
	vbox yield/category=rep FILLATTRS=(color=red) LINEATTRS=(color=black) WHISKERATTRS=(color=black);
run;

proc sgplot data=alliance;
	vbox yield/category=Col FILLATTRS=(color=yellow) LINEATTRS=(color=black) WHISKERATTRS=(color=black);
run;

proc sgplot data=alliance;
	vbox yield/category=Row FILLATTRS=(color=blue) LINEATTRS=(color=black) WHISKERATTRS=(color=black);
run;
```

In the heat map, there is a notable region where yield dips in the north west corner of the study area. This area runs across the two top most blocks and is positioned towards their ends, making those blocks non-homogeneous. As Stroup [@stroup2013] notes, this is due to a hilly area with low snow cover and high exposure to low winter temperatures. The box plots demonstrate this pattern across blocks, columns, and rows as well. From these initial graphics, it is clear there are discernible spatial patterns and trends present.<br><br>

## Estimating and Testing Spatial Correlation

### Examine the Number of Distance Pairs and Maximum Lags between Residuals

The process of modeling spatial variability begins by obtaining the residuals from the original RCB analysis. Here **PROC MIXED** is used to fit the RCB model and output the model residuals to the SAS data set "residuals".<br><br>

```{r SAS6_3, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}

ods html close;
proc mixed data=alliance;
   class Rep Entry;
   model Yield = Entry / outp=residuals;
   random Rep;
run;
ods html;
```

Examining and estimating spatial variability typically proceeds in several steps. In SAS, these can all be accomplished using **PROC VARIOGRAM**. In this first step, we summarize the potential distances (lags) between row/column positions. The **nhclasses** option sets a value for the number of lag classes or bins to try. Some trial and error here may be necessary in order to find a good setting, however, this value should be big enough to cover the range of possible distances between data row and column coordinates. Setting this initially to 40 was found to be a reasonable choice here. The **novariogram** option tells SAS to only look at these distances and not compute the empirical semivariance values yet.<br><br>

```{r SAS6_4, engine="sashtml",  engine.path=saspath, engine.opts=sasopts, include=TRUE, comment=""}

/* Examine lag distance & maxlag */
ODS html GPATH = ".\img\" ;

proc variogram data=residuals;
   compute novariogram nhclasses=40;
   coordinates xc=row yc=col;
   var resid;
run;
```

This output indicates that, with 40 bins, the minimum lag distance is approximately 1.2m and that the maximum lag distances vary from 25 to 43m in rows and columns, respectively. The histogram graphically displays the number of pairs at each lag distance bin. Ideally, we want bins that have at least 30 pairs to improve accuracy in estimation of the empirical semivariance. There is sufficient data here such that setting the maximum lag to 30 results in bins that have much more than 30 pairs and will provide an accurate estimate of semivariance. <br><br>

### Compute Moran's I and Geary's C.

Two common metrics of spatial correlation are Moran's I and Geary's c. Both these measures are essentially weighted correlations between pairs of observations and measure global and local variability, respectively. If no spatial correlation is present, Moran's I has an expected value close to 0.0 while Geary's C will be close to 1.0. The estimates for I and C can be computed and tested against these null values with the **PROC VARIOGRAM** code below. <br><br>

```{r SAS6_5, engine="sashtml",  engine.path=saspath, engine.opts=sasopts, include=TRUE, comment=""}
ODS html GPATH = ".\img\" ;

proc variogram data=residuals plots(only)=moran ;
   compute lagd=1.2 maxlag=30 novariogram autocorr(assum=nor) ;
   coordinates xc=row yc=col;
   var resid;
run;
```
Both Moran's I and Geary's C are significant here, indicating the presence of spatial correlation. The accompanying scatter plot of residuals vs lag distance also show a positive correlation where residuals increase in magnitude with increasing distance between points.<br><br>

## Estimation and Modeling of Semivariance 

### Estimating Empirical Semivariance

Using the lag distance and maximum lag values obtained in the previous steps, we can now use the **compute** statement to estimate an empirical variogram as described in Section \@ref(intro)

```{r SAS6_6, engine="sashtml", engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
ODS html GPATH = ".\img\" ;

proc variogram data=residuals plots(only)=(semivar);
   coordinates xc=Col yc=Row;
   compute lagd=1.2 maxlags=30;
  var resid;
run;
```
In the plot, the semi-variance increases as distance between points increases up to approximately 20m where it begins to level off. This type of pattern is very common for spatial relationships.<br><br>

### Fitting an Empirical Variogram Model

In Section \@ref(background), several theoretical variogram models were described. We can use **PROC VARIOGRAM** to fit and compare any number of these models. In the code below, the Gaussian, Exponential, Power, and Spherical models are fit using the **model** statement. By default when several models are listed, SAS will carry out a more sophisticated spatial modeling approach that uses combinations of these models. We, however, just want to focus on single model scenarios. Hence, the **nest=1** option is given which restricts the variogram modeling to single models only.<br><br>

```{r SAS6_7, engine="sashtml", engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
ODS html GPATH = ".\img\" ;

proc variogram data=residuals plots(only)=(fitplot);
   coordinates xc=Col yc=Row;
   compute lagd=1.2 maxlags=30;
   model form=auto(mlist=(gau, exp, pow, sph) nest=1);
  var resid;
run;
```

The table **Fit Summary** provides statistics on each variogram model fit. The AIC or SSE statistics can be used as a guide for model selection where smaller values indicate a better fit.  For this data, the Gaussian model is rated as "best", although the Spherical model is relatively similar. Given the numerically lower AIC and SSE values, however, **PROC VARIOGRAM** selects the Gaussian model and reports those semivariogram model parameter estimates in the final table. These parameter estimates will be used in the next step. The plot shown at the end provides a visual comparison each variogram model fit with the selected Gaussian model highlighted in bold.<br><br>

## Using the Estimated variogram in an Adjusted Analysis
The previous steps have:<br>
1. Diagnosed the presence and pattern of spatial variability.<br>
2. Identified and estimated the a model to describe the variability<br>

The last step is to utilize this information in a statistical analysis as outlined at the beginning of Section \@ref(background). To do this, the linear mixed model procedure **PROC MIXED** will be used to incorporate the spatial variability into the linear model variance-covariance matrix, assuming the variogram model identified above.<br>

As an initial step, for comparison purposes, the unadjusted RCB model is run first and the means saved in data set "NIN_RCBD_means".<br><br>

### Unadjusted RCBD Model

```{r SAS6_8, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}

/** Fit unadjusted RCBD model **/
ODS html GPATH = ".\img\" ;

proc mixed data=alliance ;
	class entry rep;
	model yield = entry ;
	random rep;
	lsmeans entry/cl;
	ods output LSMeans=NIN_RCBD_means;
	title1 'NIN data: RCBD';
run;
```

The F-statistic and accompanying large p-value for 'gen' indicate no differences between cultivars. This is surprising for a variety trial. The fit statistics (e.g. AIC) are helpful for model comparison, although on their own, these metrics do not have much meaning. The AIC value for this standard RCB analysis is 1221.7; let's compare that number to that for the spatially-adjusted models (in the case of AIC, smaller numbers indicate a better fitting model).  Another point of comparison is the standard error of the means: 3.8557.<br>

The next step is to try a spatially-adjusted model. This is done by adding a **repeated** statement specifying the spatial model form (Gaussian, **type=sp(gau)**) and the variables related to spatial positions in the study (row, col). The **local** option tells SAS to use a nugget parameter in the Gaussian variogram model. The second additional statement is **parms**. This gives SAS a starting place for estimating the range, sill, and nugget parameters. The values given here are taken from the **PROC VARIOGRAM** output above. While this step can be omitted, it is recommended not to do so because, on its own, **PROC MIXED** can often have trouble narrowing in on reasonable parameter estimates. One reason for the preceding variogram steps was to obtain these parameter values so **PROC MIXED** has a good starting place for estimation. As before, the estimated means (adjusted now) are saved, this time in data set "NIN_Spatial_means".<br>

### RCB Model with Spatial Covariance

```{r SAS6_9, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}

/** Fit Gaussian adjusted model **/
/** Parms statement order: Range, Sill, Nugget **/
/** Model option "local" forces nugget into model **/
ODS html GPATH = ".\img\" ;

proc mixed data=alliance maxiter=150;
	class entry;
	model yield = entry /ddfm=kr;
	repeated/subject=intercept type=sp(gau) (Row Col) local;
	parms (11) (22) (19);
	lsmeans entry/cl;
	ods output LSMeans=NIN_Spatial_means;
	title1 'NIN data: Gaussian Spatial Adjustment';
run;

```

From this output, we see the AIC value is now 1073.1. This is substantially lower than the AIC=1221.7 from the unadjusted model indicating a better model fit. Additionally, the gen effect in the model now has a low p-value (p=0.0024) giving evidence for differences among cultivars where we did not see them previously. Lastly, the standard errors for the means are now lower than those of the unadjusted model indicating an increased precision in mean estimation.<br>

### Other Spatial Adjustments
#### RCB Model with Row and Column Covariates

Spatial variability might also be addressed by including covariates in the model for row and/or column trends. The following script fits this model where rows and columns enter the model as continuous effects (not in the class statement).

```{r SAS6_10, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}

/** Row column model **/
ods html close;

proc mixed data=alliance ;
	class entry rep;
	model yield = entry  row col/ddfm=kr;
	random rep;
	lsmeans entry/cl;
	ods output LSMeans=NIN_row_col_means;
	title1 'NIN data: RCBD';
run;
ods html;

```

#### RCB with Spline Adjustment

Polynomial splines are an additional method for spatial adjustment and represent a more non-parametric method that does not rely on estimation or modeling of variograms. Instead, it uses the raw data and residuals to fit a surface to the spatial data and adjust the variance covariance matrix accordingly. **PROC MIXED**, however, does not have an option for this, so the code below moves to **PROC GLIMMIX**, the generalized Linear Mixed Model procedure in SAS. The syntax for the two procedures are very similar, so, in this example adapted from [@stroup2013], only a few changes are required. First, a random statement is added for rows and columns with a "type=rsmooth" option. This fits a spline to the residuals over the row and column axes of the study area. Second, an "effect" statement is given defining a new covariate, sm_r, which is a splined surface for raw yields over the study area. When entered into the model as a continuous covariate, this centers the data such that the resulting model residuals will have a mean of zero.

```{r SAS6_11, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}

ods html close;
/** Fit  RCBD model with Spline **/

proc glimmix data=alliance ;
	class entry rep;
	effect sp_r = spline(row col);
	model yield = entry  sp_r/ddfm=kr;
	random row col/type=rsmooth;
	lsmeans entry/cl;
	ods output LSMeans=NIN_smooth_means;
	title1 'NIN data: RCBD';
run;

ods html;

```


## Compare Estimated Means

Presence of spatial variability can also bias the mean estimates. In this data, this would result in the means ranking incorrectly relative to one another under the unadjusted model. The steps below combine the saved means from the unadjusted and spatially adjusted models above so that we can see how the ranking changes.<br><br>

```{r SAS6_12, engine="sashtml", engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}

data NIN_RCBD_means (drop=tvalue probt alpha estimate stderr lower upper df);
	set NIN_RCBD_means;
	RCB_est = estimate;
	RCB_se = stderr;
run;

data NIN_Spatial_means (drop=tvalue probt alpha estimate stderr lower upper df);
	set NIN_Spatial_means;
	Sp_est = estimate;
	Sp_se = stderr;
run;

proc sort data=NIN_RCBD_means;
	by entry;
run;

proc sort data=NIN_Spatial_means;
	by entry;
run;

data compare;
	merge NIN_RCBD_means NIN_Spatial_means;
	by entry;
run;

proc rank data=compare out=compare descending;
	var RCB_est Sp_est;
	ranks RCB_Rank Sp_Rank;
run;

proc sort data=compare;
	by  Sp_rank;
run;

proc print data=compare(obs=15);
	var entry rcb_est Sp_est rcb_se sp_se rcb_rank sp_rank;
run;
```

This comparison of the first 15 means shows some clear changes in rank. In his discussion of this data, Stroup [@stroup2013], writes:<br>

> ... Buckskin was a variety known to be a high-yielding benchmark; its mediocre mean yield in the RCB analysis despite being observed in the field outperforming all varieties in the vicinity was one symptom that the RCB analysis was giving nonsense results.
>
> --- Stroup (2013)

This high expectation for Buckskin is realized in the adjusted analysis.  Likewise, other varieties, such as NE87612 that ranked near the bottom in the RCB analysis, ranked as number 4 in the adjusted analysis. Of the top 10 varieties identified in the adjusted analysis, only 6 are found in the top 10 of the unadjusted RCB analysis. These changes in rank illustrate why consideration of spatial variability in agricultural trials is important.
<br><br>

<!--chapter:end:06-rcbd-spatial-example-SAS.Rmd-->

# Other Models - R {#model-extension-r}

```{r message=FALSE, warning=FALSE}
library(agridat); library(desplot)
library(dplyr)
library(nlme); library(spaMM)
library(lme4); library(lmerTest)
library(breedR)

# set some colors for plotting (optional)
autumn <- c("#FFFFD4", "#FED98E", "#FE9929", "#D95F0E", "#993404")
blues <- c("aliceblue", "cornflowerblue", "blue", "Navy")
vir <- hcl.colors(25, palette = "viridis", rev = TRUE)
```

Spatial models can easily be extended to fit other experimental designs such as alpha lattice and split plot, and traits with non-Gaussian distribution that are modeled using a generalized linear model. 

Below are minimal examples that omit several steps conducted in \@ref(rcbd-r) (e.g. fitting the empirical variogram) for brevity. Also, although spatial variance is incorporate into each example, we have not made an effort to ensure that each is the best fitting model for the data. The examples are intended to illustrate the correct syntax in R rather than the process of proper model fitting (which was shown in \@ref(rcbd-r)). 

## Other Experimental and Treatment Designs

### Completely randomized design 

If you are running a field experiment with a completely randomized design (CRD), you can use the `gls()` function from the **nlme** package similar to how `lme()` was used described in \@ref(rcbd-r) to build a linear model. The `gls()` function will work with balanced and unbalanced data. 
The *cochran.crd* data set evaluated the effect of sulfur treatments on potato scab infection. 
```{r}
data(cochran.crd)

ggdesplot(cochran.crd, inf~col*row,
        text = trt, cex = 1, col.regions = autumn, 
        main = "Cochran CRD")

m_crd <- gls(inf ~ trt, correlation = corExp(form = ~ row + col),
             data = cochran.crd)
```

### Multi-way Factorials 

Factorial experiments that are evaluating the effects of multiple crossed treatments are an extension of the linear mixed model (if your experimented uses RCBD), or the lienar model in the case of CRD.

The *chinloy.fractionalfactorial* evaluates the effect of different fertilizer treatments (nitrogen, phosphorus, potassium, bagasse, and filter mud press) and concentrations on sugarcane yield. The levels of {0,1,2} for all variables indicate the relative concentrations of each fertilizer. Only 2-way interactions are being evaluated. 

```{r}
data(chinloy.fractionalfactorial)

m_factor <- lme(yield ~ N + P + K + B + F + N:P + N:K + N:B + N:F, 
          random = ~ 1|block, 
          correlation = corMatern(form = ~row + col), 
          data = chinloy.fractionalfactorial)
```

### Alpha lattice

The *burgueno.alpha* data set uses an incomplete block alpha design with 16 treatment levels, 12 blocks and 3 reps. 
```{r}
data(burgueno.alpha)

ggdesplot(burgueno.alpha, yield ~ col*row, out1 = block, out2 = rep, 
        text = gen, cex = 1, col.regions = autumn, 
        main = "Burgueno Alpha Lattice")

# complicated asreml code in example

m_alpha <- lme(yield ~ gen,
               random = ~ 1|rep/block,
               data = burgueno.alpha)

m_alpha_IBD  <- remlf90(fixed  = yield ~ gen,
                      random = ~ block,
                      spatial = list(model = 'AR', 
                                 coord = burgueno.alpha[, c('col','row')]), 
                      data = burgueno.alpha)
```

### Latin square

Latin is a special example of a lattice experiment where each treatment occurs in each row and in each column. As a result, the row and column effects are used to model spatial effects. 

The *cochran.latin** data set examines the effect of an "operator" (a person) on the difference between the true plot height and operator-measured height (of wheat plots). 
```{r}
data(cochran.latin)

cochran.latin <- transform(cochran.latin, rowf = as.factor(row), colf = as.factor(col))

ggdesplot(cochran.latin, diff ~ col*row, 
        text = operator, cex = 1, col.regions = vir, 
        main = "Cochran Latin Square")

m_latin <- lmer(diff ~ operator + (1|colf) + (1|rowf),
               data = cochran.latin)
```

### Split plot

The *durban.splitplot* data set looks at the effect of fungicide on barley varieties. The main plot is fungicide (2 levels), and the sub plot is variety (70 levels). There are 4 blocks. 
```{r}
# "bed" refers to the spatial position orthogonal to row (usually called 'column')
data(durban.splitplot)

ggdesplot(durban.splitplot, yield~bed*row, col.regions = vir,
          out1 = block, out2 = fung, num = gen, 
          main = "durban splitplot")

m_sp <- lme(yield ~ fung*gen,
            random = ~ 1|block/fung, 
            correlation = corGaus(form = ~ row + bed), 
            data = durban.splitplot)
```

### Split-split plot

The *archbold.apple* data set of apple trees is examining the impact of spacing (the main plot), root stock (the split plot) and variety (the split-split plot) on fruit yield. There are 5 blocks. 
```{r}
data(archbold.apple)

archbold.apple <- transform(archbold.apple, rep=factor(rep), spacing=factor(spacing), trt=factor(trt),
                 mainp = factor(paste(row, spacing, sep="")),
                 splitp = factor(paste(row, spacing, stock, sep="")))

m_ssp <- lme(yield ~ spacing*stock*gen, 
             random = ~ 1|rep/mainp/splitp, 
             correlation = corExp(form = ~ row + pos), 
             data = archbold.apple, na.action = na.exclude)
```

#### Estimated marginal means

Emmeans can be extracted in the same way as previously described in \@ref(rcbd-r):
```{r}
library(emmeans)
preds <- emmeans(m_ssp, ~ gen | stock)
pairs(preds)
```

### Split block

also, over-dispersed count data
```{r}
# data(beall.webworms)  
# under construction
```

### Augmented design

```{r}
# lind <- read.csv("data/augmented_lind.csv")
# under construction
```



<!--chapter:end:07-model-extension-R.Rmd-->

# Other Models - SAS {#model-extension-sas}

```{r include=FALSE}
require(SASmarkdown)
saspath <- "C:/Program Files/SASHome/SASFoundation/9.4/sas.exe"
sasopts <- "-nosplash -ls 200"
knitr::opts_chunk$set(engine.path=list(sas=saspath, saslog=saspath),
                  engine.opts=list(sas=sasopts, saslog=sasopts), 
                  comment=NA)
```

## Other Experimental and Treatment Designs 

Spatial models can be extended to fit other experimental designs such as CRD, Lattice, and split plot or treatment designs such as factorials. 

Below are minimal examples that omit several steps conducted in section \@ref(rcbd-sas) (e.g. fitting the empirical variogram) for brevity. Also, although spatial variance is incorporated into each example, we have not made an effort to ensure that each is the best fitting model for the data. The examples are intended to illustrate the correct syntax rather than the complete process of proper model fitting. 

Unless indicated otherwise, these data are adapted from the R package agridat. Specific links to csv data files are given in the examples.

### Completely randomized design (CRD) 

Data: [cochran_crd.csv](https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/cochran_crd.csv)<br><br>

This study investigated the effect of sulfur on controlling scab disease in potatoes and had seven treatments (trt) measuring the percent surface area infected (inf). Row and column indices are also given. The design was a completely randomized design  with 8 control replications  and 4 treatment replications.

Two possible methods of adjustment are shown: row column trend adjustment (as suggested in agridat), and a spline adjustment.<br><br>

```{r SAS8_1, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}

ods html close;
proc format;
invalue has_NA
 'NA' = .;
run;

filename CRD url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/cochran_crd.csv";

data CRD;
    infile CRD firstobs=2 delimiter=',';
    input inf trt$ row col;
  	informat inf has_NA.;
    if inf=. then delete;
run;

proc mixed data=crd;
	class trt;
	model inf=trt row col;
run;

proc glimmix data=crd;
	class trt;
	effect sp_r = spline(row col);
	model inf=trt sp_r;
	random row col/type=rsmooth;
run;
 
ods html; 
```

### Multi-way Factorials 

Data: [chinloy_fractionalfactorial.csv](https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/chinloy_fractionalfactorial.csv)<br><br>

Factorial experiments consider multiple treatments and their combinations. The study here evaluated the effect of 5 different fertilizer treatments (nitrogen, phosphorus, potassium, bagasse, and a filter mud press), each at various concentrations, on sugarcane yield. The levels of {0,1,2} indicate the relative concentrations of each fertilizer. Because all possible treatment combinations were too numerous, only a subset were used (fractional factorial) and only 2-way interactions with nitrogen are evaluated in the model. The treatments were laid out in a randomized complete block design (block).

A Gaussian spatial model is used below.<br><br>

```{r SAS8_2, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
ods html close;

proc format;
invalue has_NA
 'NA' = .;
run;

filename FACT url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/chinloy_fractionalfactorial.csv";

data Factorial;
    infile FACT firstobs=2 delimiter=',';
    input yield block$ row col trt N P K B F;
  	informat yield has_NA.;
    if yield=. then delete;
run;
 
proc mixed data=Factorial maxiter=150;
	class block N P K B F;
	model yield = N P K B F N*P N*K N*B N*F/ ddfm=kr;
	random block;
	repeated/subject=intercept type=sp(gau) (row col) local;
	parms (6) (.25) (.21) (.1);
run;

ods html;
```

### Alpha lattice

The *burgueno.alpha* data set is set up as an incomplete block alpha design with 16 treatment levels (gen). There are 12 blocks, 2 each within 3 reps. The code below illustrates the layout of the reps and blocks. Two examples of spatial adjustment are shown: 1) assuming a Gaussian spatial adjustment, and 2) utilizing a spline adjustment.<br><br>

```{r SAS8_3, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
proc format;
invalue has_NA
 'NA' = .;
run;

filename ALPHA url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/burgueno_alpha.csv";

data Lattice;
    infile ALPHA firstobs=2 delimiter=',';
    input rep$ block$ row col gen$ yield;
  	informat yield has_NA.;
    if yield=. then delete;
run;

proc sgplot data=Lattice;
	styleattrs datacolors=(cx990F26 cx99600F cx54990F);
	HEATMAPPARM y=row x=col COLORgroup=rep/ outline; 
	refline 2.5 4.5/axis=y LINEATTRS=(color=black thickness=4) ;
title1 'Lattice: Layout of Reps';

run; 

proc sgplot data=Lattice;
	styleattrs datacolors=(cx990F26 cxCC7A88 cxB33E52 cxE6B8BF
						   cx99600F cxCCAA7A cxB3823E cxE6D2B8 
						   cx54990F cxA3CC7A cx78B33E cxCFE6B8);
	HEATMAPPARM y=row x=col COLORgroup=block/ outline; 
	refline 2.5 4.5/axis=y LINEATTRS=(color=black thickness=4) ;
	refline 4.5/axis=x LINEATTRS=(color=black thickness=4);
title1 'Lattice: Layout of Blocks';
run;
```
 
```{r SAS8_3_1, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
ods html close;

proc mixed data=Lattice ;
	class block rep gen;
	model yield = gen/ ddfm=kr;
	random rep block(rep);
	repeated/subject=intercept type=sp(gau) (row col) local;
	parms (4)(30711) (57790)(86861) (133229);
run;

proc glimmix data=Lattice ;
	class block rep gen;
	effect sp_r = spline(row col);
	model yield = gen sp_r/ ddfm=kr;
	random row col/type=rsmooth;
run;

ods html;
```



### Latin square

Latin is a special example of a lattice experiment where each treatment occurs once in each row and in each column. As a result, the row and column effects are used to model spatial effects intrinsically. 

The *cochran.latin** data set examines the effect of an 6 "operators" (persons) on the difference between the true plot height and operator-measured shoot height from 6 wheat plots. Each person measured the plots in a different order according to a Latin Square design. While this example is not strictly spatial in nature, it illustrates the setup for analysis.<br><br>

```{r SAS8_4, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
ods html close;

proc format;
invalue has_NA
 'NA' = .;
run;

filename LAT url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/cochran_latin.csv";

data Latin;
    infile LAT firstobs=2 delimiter=',';
    input row col operator$ diff;
  	informat diff has_NA.;
    if diff=. then delete;
run;

proc mixed data=latin;
	class row col operator;
	model diff = operator;
	random row col;
run;

ods html;
```

### Split plot

A split plot is a factorial treatment design with a restriction on the randomization of the factors. In this example, the *durban.splitplot* data looks at the effect of two factors: fungicide and barley varieties. The study is set up with 4 blocks. Within each block, 2 fungicides are randomized as whole or main plots. Within each fungicide treatment, 70 barley varieties are then randomized separately as subplots. The resulting analysis then breaks out separate error terms for the whole plots and the subplots. The plots are arranged into 10 rows x 56 columns ('beds'). Spatial adjustment can then be introduced on top of this structure, if needed. The examples below illustrate a spherical spatial model adjustment and a spline adjustment.<br><br>

```{r SAS8_5, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
ods html close;

proc format;
invalue has_NA
 'NA' = .;
run;

filename SPLIT url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/durban_splitplot.csv";

data splitplot;
    infile SPLIT firstobs=2 delimiter=',';
    input yield block$ gen$ fung$ row bed;
  	informat yield has_NA.;
    if yield=. then delete;
run;

proc mixed data=splitplot;
	class block gen fung row bed;
	model yield = fung gen fung*gen/outp=residuals;
	random block block*fung;
	repeated/subject=intercept type=sp(sph) (row bed) local;
	parms (7)(0.03)(0.03)(0.03) (0.01);
run;

proc glimmix data=splitplot;
	class block gen fung;
	effect sp_r = spline(row bed);
	model yield = fung gen fung*gen sp_r;
	random block block*fung;
	random row bed/type=rsmooth;
run;

ods html;
```


### Split-split plot

Like the Split-Plot above, the Split-Split-Plot is a factorial design, this time with an additional restriction on the randomization. The *archbold.apple* data used here describes the yield of apple trees under the impact of tree spacing (the whole or main plot), tree root stock (the split plot), and tree variety (the split-split plot). That is, 3 tree spacings are randomized in each block. Within those spacings, 4 root stocks are randomized separately, and then within each of those 2 varieties ('gen') are randomized. There are 5 blocks ('rep') and separate error terms for spacing, root stock, and variety are broken out in the analysis. In addition, we have row and column ('pos') information for the plots. This example uses a spline spatial adjustment.<br><br>

```{r SAS8_6, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
ods html close;

proc format;
invalue has_NA
 'NA' = .;
run;

filename SPLIT url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/archbold_apple.csv";

data sp_sp_plot;
    infile SPLIT firstobs=2 delimiter=',';
    input rep$ row pos spacing$ stock$ gen$ yield trt;
  	informat yield has_NA.;
    if yield=. then delete;
run;

proc glimmix data=sp_sp_plot;
	class rep spacing stock gen;
	effect sp_r = spline(row pos);
	model yield = spacing stock spacing*stock gen gen*spacing gen*stock gen*spacing*stock sp_r;
	random rep rep*spacing rep*stock*spacing;
	random row pos/type=rsmooth;
run;
 
 ods html;
```

### Split block or Strip plot

This study (*little.splitblock*) investigated the effects of nitrogen rates (4 levels) and harvest dates (5 dates) on sugarbeet yields using 4 blocks. Similar to a Latin square, the split block design has two main factors defined in rows and columns. Within each block the rows and columns, each representing one of the factors, are independently randomized. The effect of this in the analysis of variance is to break out separate error terms and DF for each main effect as well as their interaction. In this example the spline spatial adjustment is demonstrated.

```{r SAS8_7, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
ods html close;

proc format;
invalue has_NA
 'NA' = .;
run;

filename SPLITB url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/little_splitblock.csv";

data sb;
    infile SPLITB firstobs=2 delimiter=',';
    input row col yield harvest nitro block$;
  	informat yield has_NA.;
    if yield=. then delete;
run;

proc glimmix data=sb;
	class harvest nitro block;
	effect sp_r = spline(row col);
	model yield = harvest nitro harvest*nitro sp_r;
	random block harvest*block nitro*block harvest*nitro*block;
	random row col/type=rsmooth;
run;
 
ods html;
```


### Augmented design

The augmented experimental design occurs most commonly, if not exclusively, in plant breeding studies. It can be useful when the number of treatments is very large and the primary goal of the study is to rank or select genotypes that perform to a specified level. The number of treatments and/or limited materials often preclude complete replication of all treatments. To adjust for this, only a select set of genotypes, usually of known performance, are replicated in the design. The error estimated from these select genotypes is then utilized in the analysis to evaluate the remaining genotypes. @Burgueno2018 have a very good discussion of this design and analysis of it. The example below uses their 'P2' model and the reader is referred to @Burgueno2018 for more details.

The data used here refer to a wheat genotype evaluation study carried out near Lind Washington. The study looked at 922 lines ('name'), of which, 8 were replicated known varieties. The P2 model, mentioned above, compares the averages of replicated lines to unreplicated lines. The data steps and procedures used below define these groups in an indicator variable named d2. The response variable, 'yieldg', is converted to kilograms ('yieldkg') to facilitate computations and avoid numeric overflow errors due to large values. <br><br>



```{r SAS8_8, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
filename AUG url "https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/augmented_lind.csv";

PROC IMPORT OUT= WORK.augmented
     DATAFILE= AUG
     DBMS=CSV REPLACE;
     GETNAMES=YES;
     DATAROW=2; 
RUN;

data augmented;
	set augmented;
	if yieldg = 999999 or yieldg=. then delete; /* Remove missing values */
	prow=prow*11.7; /*convert row and column indices to feet */
	pcol=pcol*5.5;
run;

proc freq noprint data=augmented;
	tables name/out=controls;
run;

data controls;
	set controls;
	if count >1;
run;

proc sort data=controls;
	by name;
run;
     
proc sort data=augmented;
	by name;
run;

data augmented;
	merge augmented controls;
	by name;
	if count=. then d2=2; /* Unreplicated */
	else d2=1;            /* Replicated */
	yieldkg=yieldg/1000;
run;

```

Following the steps described earlier, we first fit a base model, yieldkg = d2, to obtain residuals. We cannot use a base model of `yieldkg = name` because all the unreplicated lines will produce residual values of 0. <br><br>

The residuals are then plotted in a heat map. This map shows evidence of spatial patterns and variability across the field. <br><br>

```{r SAS8_9, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
PROC mixed data=augmented;
	class name d2;
	model yieldkg = d2/noint outp=residuals ddf=229 229;
	lsmeans d2;
	*lsmeans name(d2)/slice = d2;
run;

proc sgplot data=residuals;
	HEATMAPPARM y=pRow x=pCol COLORRESPONSE=resid/ colormodel=(cx014458 cx1E8C6E cxE1FE01); 
title1 'Field Map';
run;
```

The  spatial variability evident in the residuals is then modeled as before. Only one model, power, is applicable to this data.<br><br>

```{r SAS8_10, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
/*
proc variogram data=residuals plots=pairs(thr=50) ;
   compute novariogram nhclasses=60;
   coordinates xc=prow yc=pcol;
   var resid;
run;

proc variogram data=residuals plots(only)=(semivar);
   compute lagd=6.6 maxlags=20;
   coordinates xc=prow yc=pcol;
   var resid;
run;

*/
proc variogram data=residuals plots(only)=(fitplot);
   where yieldkg ^= .;
   coordinates xc=pcol yc=pRow;
   compute lagd=6.6 maxlags=25;
   model form=auto(mlist=(gau, exp, pow, sph) nest=1);
  var resid;
run;
```

Using the variogram model parameters estimated above, an adjusted model is then fit to the P2 hypothesis of @Burgueno2018. The residuals from this model show little, if any, spatial variability remains after adjustment. 

*Note: the lsmeans statement is commented out in this example to avoid a large amount of output.*<br><br>

```{r SAS8_11, engine="sashtml", collectcode=TRUE, engine.path=saspath, include=TRUE, engine.opts=sasopts, comment=""}
PROC mixed data=augmented;
	class name d2;
	model yieldkg = d2 name(d2)/outp=adjresiduals ddf=229 229;
	lsmeans d2;
	repeated/subject=intercept type=sp(pow)(prow pcol) local;
	ods output SolutionR =parms;
	parms (0.074) (0.0051)(0.475)  ;
	*lsmeans name(d2)/slice = d2;
run;

proc sgplot data=adjresiduals;
	HEATMAPPARM y=pRow x=pCol COLORRESPONSE=resid/ colormodel=(cx014458 cx1E8C6E cxE1FE01); 
title1 'Field Map';
run;
```

<!--chapter:end:08-model-extension-SAS.Rmd-->

# Conclusion {#the-end}

## Other packages
There are several other packages for exploring and modeling spatial variability in field trials. 
é

|package |usage |
|-------------|-------------|
|[inla](https://www.r-inla.org)  | Bayesian modelling with options for spatial covariance structure |
| [Mcspatial](https://github.com/cran/McSpatial) | nonparametric spatial analysis, (no longer on CRAN) |
|[ngspatial](https://CRAN.R-project.org/package=ngspatial) | spatial models with a focus on generalized linear models |
| [sommer](https://CRAN.R-project.org/package=sommer) | mixed models, including an AR1xAr1 model |
| [spatialreg](https://r-spatial.github.io/spatialreg/) | spatial functions for areal data |
|[spANOVA](https://github.com/lrcastro/spANOVA) | spatial lag models for field trials |

The package **sommer** implements a version of the AR1xAR1 covariance structure. However, it does not estimate the parameter $\rho$. The user must specify the $\rho$ and that value is not optimized in the restricted maximum likelihood estimation. There may be another way to implement the AR1xAR1 spatial model using the package **TMB**. Both SAS and the proprietary software [asreml](https://asreml.kb.vsni.co.uk/) can implement a mixed model with this covariance structure.


A [spAMM tutorial](https://raw.githubusercontent.com/f-rousset/spaMM-ref/master/vignettePlus/MixedModels_useR2021.pdf) is available for exploring this package more. 

## Final recommendations

Spatial analysis is a big topic, but I think it is worth the effort to learn and implement in analysis of field trials. This guide provides some minimal recipes for how to incorporate spatial information into field trial statistical analysis. 

There is no denying that work is needed to develop scripts that automate this process so researchers can routinely incorporate spatial covariance into field trial analysis. Many current R tools are unwieldy to use and have insufficient options to support variety trial analysis.

Until this situation is improved, it is probably wisest to focus on using spatial models that are well-supported at this time. Any of the options implemented in the **nlme** package (or that work with that package) are decent choices with excellent support for extracting least-squares means, running ANOVA, and standard model diagnostics. Furthermore, **nlme** supports generalized linear models. **INLA** is established is supported by a large and growing user base, and **breedR** is likewise well established. 

Although these options may appear overwhelming, investigating spatial correlation in a field trial and controlling for it if necessary using any of the methods previously described is recommended over doing nothing. 




<!--chapter:end:09-conclusion.Rmd-->

# Flotsam & Jetsam

## R Session Info

```{r}
sessionInfo()
```

## References


<!--chapter:end:10-final_chapter.Rmd-->

