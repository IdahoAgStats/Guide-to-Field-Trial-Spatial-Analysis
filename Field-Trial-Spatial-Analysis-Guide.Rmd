--- 
title: "Incorporating Spatial Analysis into Agricultural Field Experiments."
author: "Julia Piaskowski"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "This includes instructions for diagnosing spatial variation in agricultural field trials and incorporating spatial variation into analysis of the trial using freely available tools in R."
---

# Preface 

## Tutorial goals

To help people conducting planned agricultural field trials to understand and  incorporate spatial variation routinely into analysis of field trials.  

current resources are focused on geospatia appications - LANDSAT data across large area, point information on soils and geology, and other information that typiically requiresa a moderate to deep understanding of obht GIS tools and spatial analytica techniques. 

Furthermore, there is not a comprehensive one-stop-shop for spatial analytical techniques for fied experiments that is also freely available. 





## Prerequisites

In order to run the scripts in this demonstration, you will to download R, avaiable free through the [Comprehensive R Archive Network](). While this is sufficient for running R scripts, You may also find it hepful to use RStudio, which provides a nice graphical user interface for R. RStudio can be downloaded [here]().

If you already have R installed, please make sure you have version 3.5.0 or newer. 

This demonstration is not intended to provide instructions on general R usage. However, There are numerous web resources for learning the Basics of R:

* 
* 
* 
*

## Packages we will use 


## Acknowledgements

## License

 



#### OLD STUFF

This is a _sample_ book written in **Markdown**. You can use anything that Pandoc's Markdown supports, e.g., a math equation $a^2 + b^2 = c^2$.

The **bookdown** package can be installed from CRAN or Github:

```{r eval=FALSE}
install.packages("bookdown")
# or the development version
# devtools::install_github("rstudio/bookdown")
```

Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading `#`.

To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): <https://yihui.name/tinytex/>.

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# Introduction {#intro}

## Why care about spatial variation?

Goal in this case is to understand and account for spatial variation. These are lattice data

## Diagnosing spatial autocorrelation

Spatial correlation is similarity of plots that are close to one another. Larger spatial gradients need to modelled indpendently - perhaps through blocking. 

### Moran's I

Moran's I, sometimes called "Global Moran's I" is similar like a correlation coefficient. It is a test for correation between units (plots in our case). 

$$ I = \frac{N}{W}\frac{\sum_i \sum_j w_{ij} (x_i - \bar{x})(x_j - \bar{x})}{\sum_i(x_i - \bar{x})^2} 
\qquad i \neq j$$

Where N is total number of spatial locations indexed by $i$ and $j$, x is the variable of interest, $w_{ij}$ are a spatial weights between each $i$ and $j$, and W is the sum of all weights. The expected values of Moran's I is $-1/(N-1)$. Values greater than that indicate positive spatial correlation (areas close to each other are similar), while values less than the expected Moran's I indicate dissimilarity as spatial distance between points decreases. 

There are several options for defining adjacent neighbors and how to weight each neighbors's influence. The two common configuations for defininig neighbors are the rook and queen configurations. These are exactly what their chess analogy suggest: "rook" defines neighbhors in an row/column fashion, while "queen" defines nieghbors in a row/column configuation an also neighbors located diagonally at a 45 degree angle from the row/column neighbors. Determining this can be somewhat complicated when working with irregularly-placed data (e.g. county seats), but is quite unambiguous for gridded data commonly seen in panned field experiments:

```{r echo=FALSE}
library(ggplot2)

na <- "Not adjacent"
o <- "Observation of interest"
n <- "Adjacent neighbor"

sp.config <- data.frame(row = rep(rep(1:5, 5), 2),
                        column = rep(rep(1:5, each = 5),2),
                        categ = c(rep(na, 5), #rook 
                                 na, na, n, na, na,
                                 na, n, o, n, na,
                                 na, na, n, na, na,
                                 rep(na, 5),
                                 rep(na, 5),  # start queen
                                 na, n, n, n, na,
                                 na, n, o, n, na,
                                 na, n, n, n, na,
                                 rep(na, 5)),
                        config = rep(c("rook", "queen"), each = 25) )

sp.config$categ <- factor(sp.config$categ, levels = c(o, n, na))

ggplot(sp.config, aes(x = row, y = column)) +
  geom_tile(aes(fill = categ), col = "black") +
  scale_fill_manual(values = c("red", "yellow", "white")) +
  facet_grid(. ~ config ) +
  theme_void() +
  coord_fixed() +
  theme(legend.title = element_blank(), 
        strip.text = element_text(size = 14),
        legend.text = element_text(size = 13))
 
```

Another test for diagnosing spatial correlation is Geary's C:

$$ I = \frac{(N -1)}{2W}\frac{\sum_i \sum_j w_{ij} (x_i - x_j)^2}{\sum_i(x_i - \bar{x})^2} \qquad i \neq j$$

These terms have the same meaning in Moran's I. The expected value of Geary's C is 1. Values higher than 1 indicate positive spatial correlation and less than 1 indicate negative spatial correlation. 

### Empirical variogram & semivariance

An empirical varigram is a visual tool for understanding how error terms are related to each other over spatial distance. It relies on semivariance ($\gamma$), a statistic expressing variance as a function of pairwise distances between data points at points $i$ and $j$.   

$$\gamma(h) = \frac{1}{2|N(h)|}\sum_{N(h)}(x_i - x_j)^2$$

Semivariances are binned for distance intervals. The average values for semivariance and distance interval can be fit to correlated error models such a exponential, spherical, gaussian and MatÃ©r. How to dothis is explored further in section 2 of this guide. 

Three important concepts of an empirical variogram are *nugget*, *sill* and  *range* 

![Example Empirical Variogram](img/Sadoti2014_spherical.jpg)

* range = distance up to which is there is spatial correlation
* sill = uncorrelated variance of the variable of interest
* nugget = measurement error,short-distance spatial variance and other unaccounted for variance

2 other concepts: 

* partial sill = sill - nugget
* nugget effect = the nugget/sill ratio, interpreted opposite of $r^2$

#### OLD STUFF

You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods).

Figures and tables with captions will be placed in `figure` and `table` environments, respectively.

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}
knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)
```

You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015].

<!--chapter:end:01-intro.Rmd-->

# Spatial Models {ch2-bg}

This section contains some of the background behind why spatial models are used and how they work. Understanding this section is not essential, but it is extremely helpful. This section relies on information introduced in part I, s please make sure you have read that section, especially if you are new to empirical variograms and spatial statistics.  

General linear statistical models are commonly modeled as thus:

$$Y_i = \beta_0 + X_i\beta_1 + \epsilon_i$$
$\beta_1$ is a slope describing the relationship between a continuous variable and the dependent variable, $Y_i$. If $X_i$ is a categorical variable, such as a crop variety, then there will be $p-1$ slopes estimated, where p is the number of unique treatements levels in $X$. 

The error terms, $\epsilon_i$ are assumed normally distributed with a mean of zero and a variance of $\sigma^2$ :

$$e_i ~\sim N(0, \sigma^2)$$
The error terms, or residuals, are assumed to be *identically* and *independently* distributed (abbreviated as "iid"). This implies a constant variance of the error terms and zero covariance between residuals. 

If N = 3, the expanded model looks like this:  

$$\left[ {\begin{array}{ccc} Y_1\\ Y_2\\ Y_3 \end{array} } \right] = \beta_0 + 
\left[ {\begin{array}{ccc} X_1\\ X_2\\ X_3 \end{array}  } \right] \beta_1 +
\left[ {\begin{array}{ccc} \epsilon_1\\ \epsilon_2\\ \epsilon_3 \end{array}  } \right] $$


$$e_i ~\sim N \Bigg( 0, 
\left[ {\begin{array}{ccc} \sigma^2 & 0 & 0 \\ 0 & \sigma^2 & 0\\ 0 & 0 & \sigma^2\end{array}  } \right] \Bigg) $$

If spatial variation is present, the off-diagonals of the variance-covariance matrix are not zero - hence the error terms are not independently distributed. As a result, hypotheses test and parameter estimates from uncorrected linear models will provide erroneous results. 

## Correlated Error Models

### Distance-based Correlation Error Models

There are mathematical tools for modelling how error terms are correlated with each other based on pairwise physical distance between observations. These models can be used to weight observations. Often, the data are assumed to be *isotropic*, where distance but not direction impacts error spatial correlation

There are several methods for estimating the semivariance as a direct function of distance.

#### Exponential Model

$$ \gamma (h)\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left [ 1-e^{-(\frac{h}{r})} \right] & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$ 

```{r Exp-CE-fig, echo=FALSE, fig.cap='Exponential Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill = 1.7
psill = sill - c0
range = 0.5
x <- seq(0,2, by = 0.01)
y <- c0 + psill*(1-exp(-1*x/range))


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range*3, lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext(expression('r'[p]), side = 1, at = range*3)
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

$3r = r_p$ is the "practical range", which is 95% of the true value for $C_1$. 


#### Gaussian
(a squared version of the exponential model)

$$ \gamma (h)\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left [ 1-e^{-(\frac{h}{r})^2} \right] & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$

```{r Gau-CE-fig, echo=FALSE, fig.cap='Gaussian Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill = 1.7
psill = sill - c0
range = 0.75
x <- seq(0,2, by = 0.01)
y <- c0 + psill*(1-exp(-1*(x/range)^2))


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range*sqrt(3), lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext(expression('r'[p]), side = 1, at = range*sqrt(3))
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

$\sqrt 3r = r_p$ is the "practical range", which is 95% of the true value for $C_1$. 

#### Spherical model

$$ \gamma (h) = \left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left[ \frac{3h}{2r}-0.5\bigg( \frac{h}{r}\bigg)^3 \right] & 0 <h \leq r \\ 
C_0 + C_1 & h > r \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$

```{r Sph-CE-fig, echo=FALSE, fig.cap='Spherical Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill <- 1.7
psill <- sill - c0
range = 1.3
x <- seq(0,2, by = 0.01)
y <- ifelse(x <= range, c0 + psill*((3*x)/(2*range) - 0.5*(x/range)^3),
            sill)

plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range, lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext('r', side = 1, at = range)
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

#### Other correlated error distance models 

There are many more models - MatÃ©rn, Cauchy, Logistic - that may describe spatial correlation in a data set. 

There are two addition models that have no range or sill, the linear model and power model. If your data fits these, consider doing a trend analysis.

#### Linear model

$$ \gamma (h)=\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1h & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = slope $$

```{r linear-CE-fig, echo=FALSE, fig.cap='Linear Error Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
plot(0, c0, xlim = c(0,2), ylim = c(0, 2), axes = F, ann = F)
lines(c(0, 2),c(c0, 1.7), xlim = c(0,2), ylim = c(0, 2), col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
points(0, c0, pch = 21, bg = "white")
mtext("h", at = 2, side = 1)
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
```

There is no sill or range in the linear model, so the variance will continue to increase as a function of distance. 

#### Power Model

$$ \gamma (h)=\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1h^\lambda & h > 0 \end{array} } \right. $$
where

$$ 0 \leq \lambda <\leq 2 \\ C_0 = nugget \\ C_1 = scaling \: factor $$
```{r power-CE-fig, echo=FALSE, fig.cap='Power Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
c1 <- 1
lambda <- 0.5
x <- seq(0,2, by = 0.01)
y <- c0 + c1*(x^lambda)


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)

```

When $\lambda = 1$, that is equivalent to the linear model. Example above is when $\lambda = 0.5$ (i.e. a square-root transformation) and $C_1 = 1$.  There is also no sill or range in the power model. 

### Correlated Error Models for Gridded Data

Planned field experiments often have the advantage of being arranged in regular grid pattern that can be adequately described using Euclidian space. This simplifies aspects of understanding how error terms are related by distance since the data occur in evenly spaced increments. Furthermore, in many agricultural trials, there may be no interest in spatial interpolation between units. Some of these models work with irregular data, but the models presented are simplified forms when experimental units are arranged in regular grid.

For example, imagine an experiment consisting of 8 plots (plot = the experiment units) arranged in 2 rows, each with 4 ranges with this layout: 

```{r plot-grid-fig, echo=FALSE, fig.asp=0.35}
# plot(1, col = "white", xlim = c(0,4), ylim = c(0,2), ann = F, xaxt = "n", yaxt = "n") # xlab = "row", ylab = "ranges")
# grid(6, 10, lty = 1, col = "black")
# mtext("ranges", side = 2, at = 1.5)
# mtext("rows", side = 1, at = 2)

library(ggplot2)

dt <- data.frame(plot = paste0("plot ",1:8), row = rep(1:2, each = 4), range = rep(1:4, 2))

ggplot(dt, aes(x = range, y = row)) +
  geom_tile(col = "black", fill = "white") +
  geom_text(aes(label = plot)) +
  scale_y_continuous(breaks = c(1, 2)) +
  theme_classic() 
```

The statistical model for that experiment:

$$ 
\left[ {\begin{array} \ Y_1 \\ Y_2 \\ \vdots \\ Y_n \end{array} } \right] = \beta_0 + 
\left[ {\begin{array} \ X_1 \\ X_2 \\ \vdots \\ X_n \end{array} } \right] \beta_1 +
\left[ {\begin{array} \ \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_n \end{array} } \right]
$$
$X\beta$ refer to independent variable effects. This same model is also often presented in an abbreviated matrix form: 

$$ \mathbf{Y = X\beta + \epsilon}$$

#### Auto-regressive Model (AR1)

This assumes that variance can be modelled as exponential function based on unit distance (e.g. row or range), either in a single direction or anistropic. 

The AR1 structure across 2 rows is modeled as thus: 

$$\mathbf { V_{AR(1)row}}  = \sigma^2
\left[ {\begin{array}{cc} 
1 & \rho \\
\rho & 1 
\end{array} } \right] \otimes \mathbf{I_4} $$

This covariance model describes the correlation of observations in the *row direction only.* 

And similarily the AR1 structure across 4 ranges is modeled as thus: 

$$ \mathbf {V_{AR(1)range}} = \sigma^2 \mathbf{I_4} \otimes
\left[ {\begin{array}{cccc} 
1 & \rho & \rho^2 & \rho^3 \\
\rho & 1 & \rho & \rho^2  \\
\rho^2 & \rho & 1 & \rho  \\
\rho^3 & \rho^2 & \rho & 1
\end{array} } \right] $$

This covariance model describes the correlation of observations in the *range direction only.* 

In combined AR1xAR1 model, the parameter, $\rho$ may need to estimated separated across the row and column directions depending on the shape of the plots and site-specific field variation. Very rectangular plots are likely to require a separate estimate of the $\rho$ parameter for each direction. 

$$ \mathbf {V_{AR(1)row} \otimes V_{AR(1)range}} = \sigma^2
\left[ {\begin{array}{cccc | cccc} 

1 & \rho_1 & \rho_1^2 & \rho_1^3 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1^3\rho_2 \\
\rho_1 & 1 & \rho_1 & \rho_1^2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2\\
\rho_1^2 & \rho_1 & 1 & \rho_1 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2\\
\rho_1^3 & \rho_1^2 & \rho_1 & 1 & \rho_1^3\rho_2 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 \\
\hline
\rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1^3\rho_2 & 1 & \rho_1 & \rho_1^2 & \rho_1^3 \\
\rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1 & 1 & \rho_1 & \rho_1^2 \\
\rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2 & \rho_1 & 1 & \rho_1 \\
\rho_1^3\rho_2 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 &\rho_1^3 & \rho_1^2 & \rho_1 & 1 \\

\end{array} } \right]
$$

**Note**: $\rho_1$ and  $\rho_2$ are the parameter estimate for $V_{AR1(1) row}$ and $V_{AR(1)range}$, respectively.

Please note that these error models are for modelling localised variation based on physical proximity. It is assumed that eventually a distance in the experiment can be reached in which 2 observations can be treated independent. 
If there are spatial trends that extend along the entire scope of an experiment (for instance, due to position on a slope), then an additional trend analysis should be conducted.

## Nearest Neighbor Approaches

These approaches look use information from adjacent plots to adjust for spatial auto-correlation. 

### Spatial Durbin Approach

This one add the average of values the neighboring independent variables to the model:

$$y = X\beta + WX\theta + \epsilon $$

### Spatial Autoregressive (SAR)

Sometimes called a "lag" model, the SAR model uses correlations with neighboring plots dependent variable to predict Y. The auto-regressive model explicitly models correlations between neighboring points. 

$$\mathbf{Y =  \rho W Y + X\beta + \epsilon} $$

While this may look strange, $\mathbf{W}$ is an $n$ x $n$ matrix weighting the neighbors with a diagonal of zero so the value at $i=j$, that is $Y_{ijk}$ itself, is not used on the right-hand side to predict $Y_{ijk}$ on the left-hand side of the equation. The error terms are assumed iid. 

### Spatial Error Model (SEM)

This is also refereed to as the "moving average model" and is quite similar to auto-regressive model. Auto-regressive models a variables's spatial dependence on nearby experimental units. 

$$\mathbf {Y= X\beta + u} \\ \mathbf {u = \lambda W + \nu}$$

Where $\mathbf{u}$ incorporates both the normally-distributed iid error and spatially correlated error. Like in SAR, $\mathbf{W}$ is a matrix of spatial weights and $\lambda$ is a parameter describing autocorrelation of the error terms. 

### ARIMA 

The AR1 and MA1 models can be combine into one: 

$$ y = X\beta + \rho W_1y+u \\ u = \lambda W_2 + \nu $$

**On Weights**

Setting weights of neighbors is dealt with in the next chapter\@ref(ch3),

## Trend Analysis

### Row, column and combined and row plus column trends.

Experiment wide-trends should be modeled with directional trend models. These are comparatively simple models:

$$Y_{ijk} = \beta_0 + X_{i1}\beta_1 +  Row_{j2}\beta_2 + Range_{k3}\beta_3 +\epsilon_{ijk}$$ 

If the assumption of independent, normal, and identical errors are met, then this model will suffice. If spatial variation is still present, additional measures will need to be taken. 

### Splines

There is a rich field of research on using localised splines to model field heterogeneity. These models are complex and hence not described. More resources can be found in the references section. 

<!--chapter:end:02-background.Rmd-->

# Example Analysis {#ch3}

## Load Data

This tutorial uses the Nebraska Interstate wheat trials, first published by Stroup et al in 1991 and reused extensively in field spatial variation studies. 

```{r message=FALSE, warning=FALSE}
library(agridat); library(dplyr); library(tidyr)
data("stroup.nin")

Nin <- stroup.nin %>% mutate(col.width = col * 1.2, row.length = row * 4.3) %>% 
  mutate(name = case_when(is.na(as.character(rep)) ~ NA_character_, 
                          TRUE ~ as.character(gen))) %>% arrange(col, row) %>% 
  mutate(plot = 1:n())

Nin.na <- filter(Nin, !is.na(rep))
```

### Examine Data

```{r}
head(Nin)
str(Nin)
```

This data set actually has no missing data -- this is a balanced trial. However, there are empty fill plot with no data which creates some issues regarding NA handling. 


Plot raw data as it appeared in the field: 
```{r message=FALSE, warning=FALSE}
library(ggplot2); library(desplot)
```


```{r Nin-yield-layout-fig, fig.height=6, message=FALSE, warning=FALSE}

ggplot(Nin, aes(x = row, y = col)) +
  geom_tile(aes(fill = yield), col = "white") +
  #geom_text(aes(label = name)) +
  geom_text(aes(label = plot)) +
  geom_tileborder(aes(group = 1, grp = rep), lwd = 1.2) +
  scale_fill_gradient(low = "white", high = "blue") +
  scale_x_continuous(breaks = seq(1,max(Nin$row), 1)) +
  scale_y_continuous(breaks = 1:max(Nin$col)) +
  labs(x = "row", y = "column", title = "field plot layout") + 
  theme_classic() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12))

```
Black lines delineate the blocks. 

```{r}
library(rayshader)
options(cores = 3)
```

```{r eval=FALSE, include=FALSE}
# this function is so slow!!
layout.gg <- ggplot(Nin, aes(x = row.length, y = col.width)) +
  geom_tile(aes(fill = yield), col = "black") +
  scale_fill_gradient(low = "white", high = "blue") +
  coord_fixed() + 
  theme_void() 

plot_gg(layout.gg, multicore = T, width = 10, height = 5, scale = 300, 
        background = "white",shadowcolor = "#3a4f70") 

render_snapshot(clear = T)
```



It's also helpful to plot raw response data: 
```{r Nin-boxplot-fig, fig.width=6, fig.asp = .6}
par(mfrow=c(1,3))
boxplot(yield ~ rep, data = Nin, xlab = "rep", ylab = "yield (bu/acres)", col = "red2", main = "yield across blocks")
boxplot(yield ~ row, data = Nin, xlab = "row", ylab = "yield (bu/acres)",col = "dodgerblue2", main = "yield across rows")
boxplot(yield ~ col, data = Nin, col = "gold", xlab = "column", ylab = "yield (bu/acres)",main = "yield across columns")
par(mfrow=c(1,1))
```

## Test for Spatial Correlation

### Moran's I

First, run a standard linear model of the experiment: 
```{r message=FALSE, warning=FALSE}
library(nlme); library(car)

nin.lme <- lme(yield ~ gen, random = ~1|rep,
              data = Nin,
              na.action = na.exclude)

Anova(nin.lme, type = "2")
```

Next, establish and weight neighbors. In this example, only adjacent neighbors in the rook formation are used and are weighted proportionally according to their representation as neighbors to an individual. That is, if a unit has 4 adjacent neighbors, each neighbor is weighted as 0.25. If there are only two neighbors, each is weighted as 0.5. 

The function `cell2nb` is a simplified function for setting neighbors when working with data laid out in a regular grid, which is a common feature of many agricultural field trials.


```{r message=FALSE, warning=FALSE}
library(spdep)
xy.rook <- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type="rook") # make sur your data sorted by the variables assigned to row and col (in that order), and there is one and only one observation in the data set for each unique row/col combination. Even missing plots need a row

```

*Rook adjacency plot for the NIN data*
```{r nin-rook-adj-fg, message=FALSE, warning=FALSE}
library(sf)
plot(xy.rook, coords = st_multipoint(matrix(c(Nin$col, Nin$row), ncol = 2)))

```
Each observation considers "neighbors" to be those which touch the cell in a row or column oriention, but not diagonal. 


Conduct Moran's test via standard t-test and using MC sampling. 
```{r}
resid.lme <- residuals(nin.lme)
names(resid.lme) <- Nin$plot
moran.test(resid.lme, nb2listw(xy.rook), na.action = na.exclude)
moran.mc(resid.lme, nb2listw(xy.rook), 999, na.action = na.exclude)
```

Plot Spatial dependence of resids

```{r resid-cor-fig, message=FALSE, warning=FALSE}
library(purrr)
res.nn1 <- map_dbl(xy.rook, function(j) mean(resid.lme[j]))
  
c <- signif(cor(resid.lme, res.nn1, use = "pairwise.complete.obs"), 2)

plot(x = resid.lme, y = res.nn1, 
     main = paste0("r = ", c), xlab = "residual", ylab = "average residual of neighbor (rook)")

```

### Note on Geary's C

At this time, the spdep function `geary.test()` for Geary's C does not handle missing spatial points. This is area to contribute to! The 
 
## Empirical Variogram Fitting

First, create a spatial object by adding spatial coordinates to an ordinary data frame. I like to use the actual units of the plots since they are exaggerated rectangals (meters in this example).

```{r}
Nin.spatial <- Nin.na
coordinates(Nin.spatial) <- ~ col.width + row.length
class(Nin.spatial)
```

Set the maximum distance for calculating the variogram model (which is one-half the maximum distance between two points).

```{r}
max_dist = 0.6*max(dist(coordinates(Nin.spatial)))
max_dist
``` 

Calculate semivariance for an istropic model and plot the variogram. 

```{r}
library(gstat)
resid.var1 <- variogram(yield ~ rep + gen, 
                        cutoff = max_dist,
                        width = max_dist/20, # 20 is the number of bins
                        data = Nin.spatial)
plot(resid.var1)
```

Test out correlated error models:

First, set the starting nugget values as the minimum of the semi-variance. There is likely more sophicated methods to establish the starting value for nugget, but I have found that extracting the minimum value of the semivariance to work well as a starting point. 

```{r}
nugget_start <- min(resid.var1$gamma)
```

Establish models for variogram fitting. 
```{r}
Nin.vgm1 <- vgm(model = "Exp", nugget = nugget_start) # exponential
Nin.vgm2 <- vgm(model = "Sph", nugget = nugget_start) # spherical
Nin.vgm3 <- vgm(model = "Gau", nugget = nugget_start) # Gaussian
```

Fit the variograms to the data:
```{r}
Nin.variofit1 <- fit.variogram(resid.var1, Nin.vgm1)
Nin.variofit2 <- fit.variogram(resid.var1, Nin.vgm2)
Nin.variofit3 <- fit.variogram(resid.var1, Nin.vgm3)
```

Look at the results! (this is fun)

```{r}

plot(resid.var1, Nin.variofit1, main = "Exponential model")
plot(resid.var1, Nin.variofit2, main = "Spherical model")
plot(resid.var1, Nin.variofit3, main = "Gaussian model")
```

How to pick the best one? Looking at how well each captures the error is the best approach. The attribute "SSError" indicates how well each model was able to predict the binned error terms as a function of distance. 

```{r}
print("Exponential"); attr(Nin.variofit1, "SSErr")
print("Spherical"); attr(Nin.variofit2, "SSErr")
print("Gaussian"); attr(Nin.variofit3, "SSErr")
```

`Nin.Variofit3` had the lowest error terms, corresponding to the Gaussian model.

Results from the empirical variogram:

```{r}
Nin.variofit3
```

The variogram parameters can be easily extracted from this table:

```{r}
nugget <- Nin.variofit3$psill[1] # "measurement error"
range <- Nin.variofit3$range[2] # distance to establish independence between data points
sill <- sum(Nin.variofit3$psill) # maximum semivariance
```


Try out Anistropic Models:

Reestablish models for variogram fitting. 
```{r}
Nin.vgm1a <- vgm(model = "Exp", anis = c(90, 0.5)) # 90 refers to the angle of the main direction and 0.5 creates a second 90 degree axis of variability to estimate 
Nin.vgm2a <- vgm(model = "Sph", anis = c(90, 0.5))
Nin.vgm3a <- vgm(model = "Gau", anis = c(90, 0.5))
```

Fit the variograms to the data:
```{r message=FALSE, warning=FALSE}
Nin.variofit1a <- fit.variogram(resid.var1, Nin.vgm1a)
Nin.variofit2a <- fit.variogram(resid.var1, Nin.vgm2a)
Nin.variofit3a <- fit.variogram(resid.var1, Nin.vgm3a)

print("Exponential"); attr(Nin.variofit1a, "SSErr")
print("Spherical"); attr(Nin.variofit2a, "SSErr")
print("Gaussian"); attr(Nin.variofit3a, "SSErr")
```

Error terms are considerably higher than in the anistropic model!

```{r}
plot(resid.var1, Nin.variofit1a, main = "Exponential model")
```

Hmm, that plot is not very convincing. 

In this field trial, there is evidence spatial correlation as a function of distance, but there is not evidence that spatial autocorrelation is impacted by the direction.

It's important to remember these methods are intended to describe localised spatial correlation. Field-wide spatial gradients should be modelled as a separate trend. 


<!--chapter:end:03-example-identifying-spatial-var.Rmd-->

# Applying Spatial Covariates {#ch4}


```{r message=FALSE, warning=FALSE}
library(agridat); library(dplyr); library(tidyr)
data("stroup.nin")

Nin <- stroup.nin %>% mutate(col.width = col * 1.2, row.length = row * 4.3) %>% 
  mutate(name = case_when(is.na(as.character(rep)) ~ NA_character_, 
                          TRUE ~ as.character(gen))) %>% arrange(col, row) 

Nin.na <- filter(Nin, !is.na(rep))

Nin.spatial <- Nin.na
coordinates(Nin.spatial) <- ~ col.width + row.length

```

Once spatial autocorrelation has been identified in field trials, the next logical step is to employ a modelling technique that will reduce the impact of spatial varition on the final estiamtes from the analysis.  

## Prep work

As a reminder, the first thing is to run a standard linear model. A common model specification for the randomised complete block design (RCBD) is to include cultivar as a fixed effect and block as a random effect. 

Here is the R code for RCBD analsysis of the NIN data set loaded in Section 3 \@ref(ch:ch3) that was found to have strong spatial correlation:

```{r message=FALSE, warning=FALSE}
library(nlme)

nin.lme <- lme(yield ~ gen, random = ~1|rep,
              data = Nin,
              na.action = na.exclude)

anova(nin.lme)
```

```{r}
library(spdep)
xy.rook <- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type="rook") 
moran.test(residuals(nin.lme), nb2listw(xy.rook), na.action = na.exclude)
```

The variables "gen" refers to the cultivar or breeding line being trialled, and "rep" is the block, and the dependent variable, "yield" is grain yield. Basic exploratory analysis was conducted in Section 3 \@ref(ch:ch3). 

## Correlated Errors I: spatial distance 

**Gaussian Example**

In order to fit models using correlated error model, we will need to first obtain preliminary estimates of the nugget, sill and range: from fitting an empirical variogram. 

```{r}
library(gstat)
max_dist <- 0.6*max(dist(coordinates(Nin.spatial)))
resid.var1 <- variogram(yield ~ rep + gen, 
                        cutoff = max_dist,
                        width = max_dist/29, 
                        data = Nin.spatial)
nugget_start <- min(resid.var1$gamma)
``` 


```

Nin.vgm1 <- vgm(model = "Exp", nugget = nugget_start) 
Nin.vgm2 <- vgm(model = "Sph", nugget = nugget_start) 

Nin.vgm4 <- vgm(model = "Mat", nugget = nugget_start)

Nin.variofit1 <- fit.variogram(resid.var1, Nin.vgm1)
Nin.variofit2 <- fit.variogram(resid.var1, Nin.vgm2)

Nin.variofit4 <- fit.variogram(resid.var1, Nin.vgm4)
```

In the previous section, an isotropic Gaussian function was identified as the best mocel for describing the decay of eror correlation over distance.

```{r}
Nin.vgm <- vgm(model = "Gau", nugget = nugget_start) 
Nin.variofit <- fit.variogram(resid.var1, Nin.vgm)

nugget <- Nin.variofit$psill[1] 
range <- Nin.variofit$range[2] 
sill <- sum(Nin.variofit$psill) 
nugget.effect <-  nugget/sill
```

Next, create a correlated error structure (from the **nlme** package).
```{r}
cor.gaus <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "gaussian", 
                  metric = "euclidean")
```

Last, update the linear mixed model with the correlated error strucutre and inspect the results:
```{r}
nin.gaus <- update(nin.lme, corr = cor.gaus)
anova(nin.gaus)
#moran.test(residuals(nin.gaus), nb2listw(xy.rook), na.action = na.exclude)
```

Other models can be implemented quite similarily:

### Exponential

```{r}
rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect)

Nin.vgm <- vgm(model = "Exp", nugget = nugget_start) 
Nin.variofit <- fit.variogram(resid.var1, Nin.vgm)

nugget <- Nin.variofit$psill[1] 
range <- Nin.variofit$range[2] 
sill <- sum(Nin.variofit$psill) 
nugget.effect <-  nugget/sill

cor.exp <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "exponential", 
                  metric = "euclidean")

nin.exp <- update(nin.lme, corr = cor.exp)
anova(nin.exp)
```

### Spherical

```{r}
rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect)

Nin.vgm <- vgm(model = "Sph", nugget = nugget_start) 
Nin.variofit <- fit.variogram(resid.var1, Nin.vgm)

nugget <- Nin.variofit$psill[1] 
range <- Nin.variofit$range[2] 
sill <- sum(Nin.variofit$psill) 
nugget.effect <-  nugget/sill

cor.sph <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "spherical", 
                  metric = "euclidean")

nin.sph <- update(nin.lme, corr = cor.sph)
anova(nin.sph)
```

### Power

```{r}
rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect)

cor.pow <- corSpatial(form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "ratio", 
                  metric = "euclidean")

nin.pow <- update(nin.lme, corr = cor.pow)
anova(nin.pow)
```

In the **nlme* package, there is also an option for a linear model in the `corSpatial()` function. However, it is recommended that a linear trend be fitted to the data instead. 

The package **spaMM* implements additional correlation models such as MatÃ©rn, Cauchy and more. 

## Nearest Neighbor Approaches

### estimating lagged autocorrelation

Prior to running any nearest neighbor appraoches, it is helpful to understand the lagged spatial autocorrelation. 

### Durban
??

### Spatial lag model

```{r message=FALSE, warning=FALSE}
library(spatialreg)

nin.lag <- lagsarlm(yield ~ gen + rep,
                       listw = nb2listw(xy.rook),
                       data = Nin, na.action = na.exclude)

moran.mc(residuals(nin.lag), nb2listw(xy.rook), 999, na.action = na.exclude)
```

### Spatial error model

```{r}
nin.sem <- errorsarlm(yield ~ gen + rep,
                       listw = nb2listw(xy.rook),
                       data = Nin, na.action = na.exclude)

moran.mc(residuals(nin.sem), nb2listw(xy.rook), 999, na.action = na.exclude)
```

### Combined spatial lag and error model (ARMA)

```{r}
nin.arma <- sacsarlm(yield ~ gen + rep,
                       listw = nb2listw(xy.rook),
                       data = Nin, na.action = na.exclude)

moran.mc(residuals(nin.arma), nb2listw(xy.rook), 999, na.action = na.exclude)
```


## p-Splines


### AR1xAR1 (not possible!!)

<!--chapter:end:04-example-applying-spatial-covars.Rmd-->

# Comparing Spatial Models {#ch3-part3}


## Example one


## Example two



<!--chapter:end:05-spatial-model-evaluation.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:06-references.Rmd-->

