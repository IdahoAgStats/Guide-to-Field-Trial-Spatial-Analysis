--- 
title: "Incorporating Spatial Analysis into Agricultural Field Experiments."
author: "Julia Piaskowski"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "This includes instructions for diagnosing spatial variation in agricultural field trials and incorporating spatial variation into analysis of the trial using freely available tools in R."
---

# Preface

```{r, echo=FALSE,out.width="90%",fig.align='center'}
knitr::include_graphics("img/stats_help.jpg")
```
<center>

Image from [Discovering Statstics](https://www.discoveringstatistics.com/2016/04/28/if-youre-not-doing-something-different-youre-not-doing-anything-at-all/)

</center>

## Tutorial goal

*To help people conducting planned agricultural field trials understand and incorporate spatial variation routinely into analysis of field trials.*

Current educational resources are focused largely on geospatial appications that typically require a a moderate to deep understanding of  mapping tools and spatial analytical techniques. Furthermore, there is not a comprehensive resources for spatial analytical techniques for field experiments that is also freely available. This tutorial is intended to fill that gap. 

## Prerequisites

In order to run the scripts in this demonstration, you will to download R, avaiable free through the [Comprehensive R Archive Network](https://cran.r-project.org/) (CRAN). While this is sufficient for running R scripts, You may also find it hepful to use RStudio, which provides a nice graphical user interface for R. RStudio can be downloaded [here](https://www.rstudio.com/products/rstudio/download/).

If you already have R installed, please make sure you have version 3.5.0 or newer. 

This demonstration is not intended to provide instructions on general R usage. However, There are numerous web resources for learning the Basics of R. [Software carpentry](https://software-carpentry.org/lessons/) offers several lesson plans covering the foundation of R.  

## Packages used in this tutorial 

|package |usage |
|------------|---------------|
|dplyr, tidyr | basic data manipulation | 
| purrr | data summary | 
|ggplot, desplot | plotting | 
|agridat | for loading a demonstration data set |
| sp, sf | for manipulating spatial objects | 
|spdep | multiple functions for spatial dependence | 
|gstat | empirical variogram | 
|nlme | mixed model analysis | 
| emmeans| for extracting least squares means |
|SpATS | spatial splines for field trials |
|sommer | mixed models with AR1xAR1 approximation |

All packages are available on CRAN.

## Contributors

[Julia Piaskowski](mailto:jpiaskowski@uidaho.edu) is the main author of this resource. 

This book was written with [bookdown](https://bookdown.org/yihui/bookdown)

## License

Incorporating Spatial Analysis into Agricultural Field Experiments by Julia Piaskowski is licensed under a [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-nc/4.0/)

```{r, echo=FALSE,out.width="20%",fig.align='center'}
knitr::include_graphics(c("img/CC-by-nc.png"))
```



```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown', 'gstat',
  'dplyr','ggplot2', 'nlme', 'car', 'sf', 'spdep', 'spreg',
  'sommer'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# Introduction {#intro}

## Why care about spatial variation?

The goal of variety testing programs is to provide the agricultural industry reliable information about regional crop variety performance. Crop variety trials employ common experimental designs such as randomised complete block design to account for environmental heterogeneity. However, those techniques are quite often inadequate to fully account for spatial heterogeneity that arises due to field position, soil conditions, disease, wildlife impacts and more. 

As a result, the assumption of ANOVA are violated, invalidating the analysis, and variety estimates themselves are incorrect. Incorporating spatial correlation between experimental plots can improve the overall accuracy and precision of these estimates. 

## Diagnosing spatial auto-correlation

Spatial correlation is similarity of plots that are close to one another.  That correlation is expected to decline with distance. This is different from experiment-wide gradients, such as a salinity gradient or position on a slope. 

### Moran's I

Moran's I, sometimes called "Global Moran's I" is similar like a correlation coefficient. It is a test for correlation between units (plots in our case). 

$$ I = \frac{N}{W}\frac{\sum_i \sum_j w_{ij} (x_i - \bar{x})(x_j - \bar{x})}{\sum_i(x_i - \bar{x})^2} 
\qquad i \neq j$$

Where N is total number of spatial locations indexed by $i$ and $j$, x is the variable of interest, $w_{ij}$ are a spatial weights between each $i$ and $j$, and W is the sum of all weights. The expected values of Moran's I is $-1/(N-1)$. Values greater than that indicate positive spatial correlation (areas close to each other are similar), while values less than the expected Moran's I indicate dissimilarity as spatial distance between points decreases. 

There are several options for defining adjacent neighbors and how to weight each neighbor's influence. The two common configurations for defining neighbors are the rook and queen configurations. These are exactly what their chess analogy suggest: "rook" defines neighbors in an row/column fashion, while "queen" defines neighbors in a row/column configuration an also neighbors located diagonally at a 45 degree angle from the row/column neighbors. Determining this can be somewhat complicated when working with irregularly-placed data (e.g. county seats), but is quite unambiguous for gridded data commonly seen in panned field experiments:

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)

na <- "Not adjacent"
o <- "Observation of interest"
n <- "Adjacent neighbor"

sp.config <- data.frame(row = rep(rep(1:5, 5), 2),
                        column = rep(rep(1:5, each = 5),2),
                        categ = c(rep(na, 5), #rook 
                                 na, na, n, na, na,
                                 na, n, o, n, na,
                                 na, na, n, na, na,
                                 rep(na, 5),
                                 rep(na, 5),  # start queen
                                 na, n, n, n, na,
                                 na, n, o, n, na,
                                 na, n, n, n, na,
                                 rep(na, 5)),
                        config = rep(c("rook", "queen"), each = 25) )

sp.config$categ <- factor(sp.config$categ, levels = c(o, n, na))

ggplot(sp.config, aes(x = row, y = column)) +
  geom_tile(aes(fill = categ), col = "black") +
  scale_fill_manual(values = c("red", "yellow", "white")) +
  facet_grid(. ~ config ) +
  theme_void() +
  coord_fixed() +
  theme(legend.title = element_blank(), 
        strip.text = element_text(size = 14),
        legend.text = element_text(size = 13))
 
```

Another test for diagnosing spatial correlation is Geary's C:

$$ I = \frac{(N -1)}{2W}\frac{\sum_i \sum_j w_{ij} (x_i - x_j)^2}{\sum_i(x_i - \bar{x})^2} \qquad i \neq j$$

These terms have the same meaning in Moran's I. The expected value of Geary's C is 1. Values higher than 1 indicate positive spatial correlation and less than 1 indicate negative spatial correlation. 

### Empirical variogram & semivariance

An empirical variogram is a visual tool for understanding how error terms are related to each other over spatial distance. It relies on semivariance ($\gamma$), a statistic expressing variance as a function of pairwise distances between data points at points $i$ and $j$.   

$$\gamma(h) = \frac{1}{2|N(h)|}\sum_{N(h)}(x_i - x_j)^2$$

Semivariances are binned for distance intervals. The average values for semivariance and distance interval can be fit to correlated error models such a exponential, spherical, Gaussian and MatÃ©rn. How to do this is explored further in \@ref(ch:ch2) of this guide. 

Three important concepts of an empirical variogram are *nugget*, *sill* and  *range* 

![Example Empirical Variogram](img/Sadoti2014_spherical.jpg)

* range = distance up to which is there is spatial correlation
* sill = uncorrelated variance of the variable of interest
* nugget = measurement error, or short-distance spatial variance and other unaccounted for variance

**2 other concepts:** 

* partial sill = sill - nugget
* nugget effect = the nugget/sill ratio, interpreted opposite of $r^2$

<!--chapter:end:02-intro.Rmd-->

# Spatial Models {#background}

This section contains some of the background behind why spatial models are used and how they work. Understanding this section is not essential, but it is extremely helpful. This section relies on information introduced in \@ref(ch:ch1), so please make sure you have read that section if you are new to empirical variograms and spatial statistics.  

General linear statistical models are commonly modelled as thus:

$$Y_i = \beta_0 + X_i\beta_1 + \epsilon_i$$
$\beta_1$ is a slope describing the relationship between a continuous variable and the dependent variable, $Y_i$. If $X_i$ is a categorical variable, such as a crop variety, then there will be $p-1$ slopes estimated, where p is the number of unique treatments levels in $X$. 

The error terms, $\epsilon_i$ are assumed normally distributed with a mean of zero and a variance of $\sigma^2$ :

$$e_i ~\sim N(0, \sigma^2)$$
The error terms, or residuals, are assumed to be *identically* and *independently* distributed (abbreviated  "iid"). This implies a constant variance of the error terms and zero covariance between residuals. 

If N = 3, the expanded model looks like this:  

$$\left[ {\begin{array}{ccc} Y_1\\ Y_2\\ Y_3 \end{array} } \right] = \beta_0 + 
\left[ {\begin{array}{ccc} X_1\\ X_2\\ X_3 \end{array}  } \right] \beta_1 +
\left[ {\begin{array}{ccc} \epsilon_1\\ \epsilon_2\\ \epsilon_3 \end{array}  } \right] $$


$$e_i ~\sim N \Bigg( 0, 
\left[ {\begin{array}{ccc} \sigma^2 & 0 & 0 \\ 0 & \sigma^2 & 0\\ 0 & 0 & \sigma^2\end{array}  } \right] \Bigg) $$

If spatial variation is present, the off-diagonals of the variance-covariance matrix are not zero - hence the error terms are not independently distributed. As a result, hypotheses test and parameter estimates from uncorrected linear models will provide erroneous results. 

## Correlated error models

### Distance-based correlation error models

There are mathematical tools for modelling how error terms are correlated with each other based on pairwise physical distance between observations. These models can be used to weight observations. Often, the data are assumed to be *isotropic*, where distance but not direction impacts the spatial error correlation.

There are several methods for estimating the semivariance as a direct function of distance.

#### Exponential

$$ \gamma (h)\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left [ 1-e^{-(\frac{h}{r})} \right] & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$ 

```{r Exp-CE-fig, echo=FALSE, fig.cap='Exponential Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill = 1.7
psill = sill - c0
range = 0.5
x <- seq(0,2, by = 0.01)
y <- c0 + psill*(1-exp(-1*x/range))


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range*3, lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext(expression('r'[p]), side = 1, at = range*3)
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

$3r = r_p$ is the "practical range", which is 95% of the true value for $C_1$. 


#### Gaussian
(a squared version of the exponential model)

$$ \gamma (h)\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left [ 1-e^{-(\frac{h}{r})^2} \right] & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$

```{r Gau-CE-fig, echo=FALSE, fig.cap='Gaussian Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill = 1.7
psill = sill - c0
range = 0.75
x <- seq(0,2, by = 0.01)
y <- c0 + psill*(1-exp(-1*(x/range)^2))


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range*sqrt(3), lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext(expression('r'[p]), side = 1, at = range*sqrt(3))
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

$\sqrt 3r = r_p$ is the "practical range", which is 95% of the true value for $C_1$. 

#### Spherical

$$ \gamma (h) = \left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1 \left[ \frac{3h}{2r}-0.5\bigg( \frac{h}{r}\bigg)^3 \right] & 0 <h \leq r \\ 
C_0 + C_1 & h > r \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = partial \: sill \\ r = range$$

```{r Sph-CE-fig, echo=FALSE, fig.cap='Spherical Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
sill <- 1.7
psill <- sill - c0
range = 1.3
x <- seq(0,2, by = 0.01)
y <- ifelse(x <= range, c0 + psill*((3*x)/(2*range) - 0.5*(x/range)^3),
            sill)

plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
abline(h = sill, lty = 2)
abline(v = range, lty = 2)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
mtext('r', side = 1, at = range)
mtext(expression('C'[0]+'C'[1]), side = 2, at = sill, las = 2)
```

#### Other correlated error distance models 

There are many more models - MatÃ©rn, Cauchy, Logistic - that may describe spatial correlation in a data set. 

There are two addition models that have no range or sill, the linear model and power model. If your data fits these, consider doing a trend analysis.

#### Linear

$$ \gamma (h)=\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1h & h > 0 \end{array} } \right. $$
where

$$ C_0 = nugget \\ C_1 = slope $$

```{r linear-CE-fig, echo=FALSE, fig.cap='Linear Error Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
plot(0, c0, xlim = c(0,2), ylim = c(0, 2), axes = F, ann = F)
lines(c(0, 2),c(c0, 1.7), xlim = c(0,2), ylim = c(0, 2), col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
points(0, c0, pch = 21, bg = "white")
mtext("h", at = 2, side = 1)
mtext(expression('C'[0]), side = 2, at = c0, las = 2)
```

There is no sill or range in the linear model, so the variance will continue to increase as a function of distance. 

#### Power

$$ \gamma (h)=\left\{ {\begin{array}{cc} 0 & h = 0\\ C_0+C_1h^\lambda & h > 0 \end{array} } \right. $$
where

$$ 0 \leq \lambda <\leq 2 \\ C_0 = nugget \\ C_1 = scaling \: factor $$
```{r power-CE-fig, echo=FALSE, fig.cap='Power Model', out.width='70%', fig.asp=0.75, fig.align='center'}
c0 <- 0.5
c1 <- 1
lambda <- 0.5
x <- seq(0,2, by = 0.01)
y <- c0 + c1*(x^lambda)


plot(x, y, xlim = c(0,2), ylim = c(0, 2), axes = F, pch = 21, bg = "black", ann = F, type = "l", col = "dodgerblue", lwd = 2)
arrows(0, 0, 0, 2, code = 2) 
arrows(0, 0, 2, 0, code = 2)
mtext(expression(paste(gamma, "(h)")), at = 2, side = 2, las = 2)
mtext("h", at = 2, side = 1)
points(0, c0, pch = 21, bg = "white")
mtext(expression('C'[0]), side = 2, at = c0, las = 2)

```

When $\lambda = 1$, that is equivalent to the linear model. Example above is when $\lambda = 0.5$ (i.e. a square-root transformation) and $C_1 = 1$.  There is also no sill or range in the power model. 

#### MatÃ©rn

$$\gamma(h) = c_0 + c_1 \bigg( 1- \frac{1}{2^{\kappa -1}\Gamma(\kappa)}
\Big( \frac{h}{\alpha} \Big) ^{\kappa} K_\kappa
\Big( \frac{h}{\alpha} \Big)    \bigg)$$

Where

$$ C_0 = nugget \\ C_1 = partial \: scale \\ 
\alpha = smoothing \: factor \\
$$

and $\kappa(\alpha)$ is a modified bessel function: 

$$ K_\kappa(t) = \frac{\Gamma(\alpha)}{2} \big( \frac{t}{2} \big) ^{-\kappa}$$

### Correlated error model for gridded data

Planned field experiments often have the advantage of being arranged in regular grid pattern that can be adequately described using Euclidean space. This simplifies aspects of understanding how error terms are related by distance since the data occur in evenly spaced increments. Furthermore, in many agricultural trials, there may be no interest in spatial interpolation between units. Some of the following models work with irregularly-spaced data, but the models below are simplified forms when the experimental units are arranged in regular grid.

For example, imagine an experiment consisting of 8 plots (plot = the experiment units) arranged in 2 rows, each with 4 ranges with this layout: 

```{r plot-grid-fig, echo=FALSE, fig.asp=0.35, message=FALSE, warning=FALSE}
# plot(1, col = "white", xlim = c(0,4), ylim = c(0,2), ann = F, xaxt = "n", yaxt = "n") # xlab = "row", ylab = "ranges")
# grid(6, 10, lty = 1, col = "black")
# mtext("ranges", side = 2, at = 1.5)
# mtext("rows", side = 1, at = 2)

library(ggplot2)

dt <- data.frame(plot = paste0("plot ",1:8), row = rep(1:2, each = 4), range = rep(1:4, 2))

ggplot(dt, aes(x = range, y = row)) +
  geom_tile(col = "black", fill = "white") +
  geom_text(aes(label = plot)) +
  scale_y_continuous(breaks = c(1, 2)) +
  theme_classic() 
```

The statistical model for that experiment:

$$ 
\left[ {\begin{array} \ Y_1 \\ Y_2 \\ \vdots \\ Y_n \end{array} } \right] = \beta_0 + 
\left[ {\begin{array} \ X_1 \\ X_2 \\ \vdots \\ X_n \end{array} } \right] \beta_1 +
\left[ {\begin{array} \ \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_n \end{array} } \right]
$$
$X\beta$ refer to independent variable effects. This same model is also often presented in an abbreviated matrix form: 

$$ \mathbf{Y = X\beta + \epsilon}$$

#### First order auto-regressive model (AR1)

This assumes that variance can be modelled as exponential function based on unit distance (e.g. row or range), either in a single direction or anistropic. 

The AR1 structure across 2 rows is modeled as thus: 

$$\mathbf { V_{AR(1)row}}  = \sigma^2
\left[ {\begin{array}{cc} 
1 & \rho \\
\rho & 1 
\end{array} } \right] \otimes \mathbf{I_4} $$

This covariance model describes the correlation of observations in the *row direction only.* 

And similarly the AR1 structure across 4 ranges is modeled as thus: 

$$ \mathbf {V_{AR(1)range}} = \sigma^2 \mathbf{I_4} \otimes
\left[ {\begin{array}{cccc} 
1 & \rho & \rho^2 & \rho^3 \\
\rho & 1 & \rho & \rho^2  \\
\rho^2 & \rho & 1 & \rho  \\
\rho^3 & \rho^2 & \rho & 1
\end{array} } \right] $$

This covariance model describes the correlation of observations in the *range direction only.* 

In combined AR1xAR1 model, the parameter, $\rho$ may need to estimated separated across the row and column directions depending on the shape of the plots and site-specific field variation. Very rectangular plots are likely to require a separate estimate of the $\rho$ parameter for each direction. 

$$ \mathbf {V_{AR(1)row} \otimes V_{AR(1)range}} = \sigma^2
\left[ {\begin{array}{cccc | cccc} 

1 & \rho_1 & \rho_1^2 & \rho_1^3 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1^3\rho_2 \\
\rho_1 & 1 & \rho_1 & \rho_1^2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2\\
\rho_1^2 & \rho_1 & 1 & \rho_1 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2\\
\rho_1^3 & \rho_1^2 & \rho_1 & 1 & \rho_1^3\rho_2 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 \\
\hline
\rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1^3\rho_2 & 1 & \rho_1 & \rho_1^2 & \rho_1^3 \\
\rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2\rho_2 & \rho_1 & 1 & \rho_1 & \rho_1^2 \\
\rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 & \rho_1\rho_2 & \rho_1^2 & \rho_1 & 1 & \rho_1 \\
\rho_1^3\rho_2 & \rho_1^2\rho_2 & \rho_1\rho_2 & \rho_2 &\rho_1^3 & \rho_1^2 & \rho_1 & 1 \\

\end{array} } \right]
$$

**Note**: $\rho_1$ and  $\rho_2$ are the parameter estimate for $V_{AR1(1) row}$ and $V_{AR(1)range}$, respectively.

Please note that these error models are for modelling localised variation based on physical proximity. It is assumed that eventually a distance in the experiment can be reached in which 2 observations can be treated independent. 
If there are spatial trends that extend along the entire scope of an experiment (for instance, due to position on a slope), then an additional trend analysis should be conducted.

## Spatial Regression methods

These approaches look use information from adjacent plots to adjust for spatial auto-correlation. 

### Spatial autoregressive (SAR)

Sometimes called a "lag" model, the SAR model uses correlations with neighboring plots dependent variable to predict Y. The auto-regressive model explicitly models correlations between neighboring points. 

$$\mathbf{Y =  \rho W Y + X\beta + \epsilon} $$

While this may look strange, $\mathbf{W}$ is an $n$ x $n$ matrix weighting the neighbors with a diagonal of zero so the value at $i=j$, that is $Y_{ijk}$ itself, is not used on the right-hand side to predict $Y_{ijk}$ on the left-hand side of the equation. The error terms are assumed iid. 

### Spatial error model (SEM)

This is also refereed to as the "moving average model" and is quite similar to auto-regressive model. SAR models the spatial dependence of the variable of interest. SEM models the spatial dependence of the error terms. 

$$\mathbf {Y= X\beta + u} \\ \mathbf {u = \lambda W + \nu}$$

Where $\mathbf{u}$ incorporates both the normally-distributed iid error and spatially correlated error. Like in SAR, $\mathbf{W}$ is a matrix of spatial weights and $\lambda$ is a parameter describing auto-correlation of the error terms. 

### ARIMA 

The AR1 and MA1 models can be combine into one: 

$$ y = X\beta + \rho W_1y+u \\ u = \lambda W_2 + \nu $$

**On Weights**

Setting weights of neighbors is dealt with in the next chapter\@ref(ch3),

## Trend analysis

### Row and column trends

Experiment wide-trends should be modeled with directional trend models. These are comparatively simple models:

$$Y_{ijk} = \beta_0 + X_{i1}\beta_1 +  Row_{j2}\beta_2 + Range_{k3}\beta_3 +\epsilon_{ijk}$$ 

If the assumption of independent, normal, and identical errors are met, then this model will suffice. If spatial variation is still present, additional measures will need to be taken. 

### Splines

There is a rich field of research on using localised splines to model field heterogeneity. These models are complex and hence not described here.  

<!--chapter:end:03-background.Rmd-->

# Example Analysis {#example-spatial-var}

## Load data

This tutorial uses the Nebraska Interstate wheat trials, first published by Stroup et al in 1991 and reused extensively in field spatial variation studies. 

```{r message=FALSE, warning=FALSE}
library(agridat); library(dplyr); library(tidyr)
data("stroup.nin")

Nin <- stroup.nin %>% mutate(col.width = col * 1.2, 
                             row.length = row * 4.3) %>% 
  mutate(name = case_when(is.na(as.character(rep)) ~ NA_character_, 
                          TRUE ~ as.character(gen))) %>% 
  arrange(col, row)

Nin.na <- filter(Nin, !is.na(rep))
```

### Examine data

```{r}
head(Nin)
str(Nin)
```

This data set actually has no missing data -- this is a balanced trial. However, there are empty fill plot with no data which creates some issues regarding NA handling. 

Plot raw yield data as it appeared in the field: 
```{r message=FALSE, warning=FALSE}
library(ggplot2); library(desplot)
```


```{r Nin-yield-layout-fig, out.width="80%",fig.asp=.7,message=FALSE, warning=FALSE}

ggplot(Nin, aes(x = row, y = col)) +
  geom_tile(aes(fill = yield), col = "white") +
  geom_text(aes(label = name)) +
  geom_tileborder(aes(group = 1, grp = rep), lwd = 1.2) +
  scale_fill_gradient(low = "white", high = "blue") +
  scale_x_continuous(breaks = seq(1,max(Nin$row), 1)) +
  scale_y_continuous(breaks = 1:max(Nin$col)) +
  labs(x = "row", y = "column", title = "field plot layout") + 
  theme_classic() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12))

```

Black lines delineate the blocks. 

It's also helpful to plot raw response data: 
```{r Nin-boxplot-fig, out.width="80%",fig.asp = .6}
par(mfrow=c(1,3))
boxplot(yield ~ rep, data = Nin, xlab = "rep", ylab = "yield (bu/acres)", col = "red2", main = "yield across blocks")
boxplot(yield ~ row, data = Nin, xlab = "row", ylab = "yield (bu/acres)",col = "dodgerblue2", main = "yield across rows")
boxplot(yield ~ col, data = Nin, col = "gold", xlab = "column", ylab = "yield (bu/acres)",main = "yield across columns")
par(mfrow=c(1,1))
```

## Test for spatial correlation

### Moran's I

First, run a standard linear model of the experiment: 
```{r message=FALSE, warning=FALSE}
library(nlme)

nin.lme <- lme(yield ~ gen, random = ~1|rep,
              data = Nin,
              na.action = na.exclude)
```

Next, establish and weight neighbors. In this example, only adjacent neighbors in the rook formation are used and are weighted proportionally according to their representation as neighbors to an individual. That is, if a unit has 4 adjacent neighbors, each neighbor is weighted as 0.25. If there are only two neighbors, each is weighted as 0.5. 

The function `cell2nb()` is a simplified function for setting neighbors when working with data laid out in a regular grid. 

```{r message=FALSE, warning=FALSE}
library(spdep)
xy.rook <- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type="rook") # make sure your data sorted by the variables assigned to row and col (in that order), and there is one and only one observation in the data set for each unique row/col combination. Even missing plots need a row
```

*Rook adjacency plot for the NIN data*
```{r nin-rook-adj-fg, message=FALSE, warning=FALSE, fig.cap='Rook adjacency plot for the NIN data'}
library(sf)
plot(xy.rook, coords = st_multipoint(matrix(c(Nin$col, Nin$row), ncol = 2)))

```
Each observation considers "neighbors" to be those which touch the cell in a row or column orientation, but not diagonal. 

Conduct Moran's test via standard t-test and using MC sampling. 
```{r}
resid.lme <- residuals(nin.lme)
names(resid.lme) <- Nin$plot
moran.test(resid.lme, nb2listw(xy.rook), na.action = na.exclude)
moran.mc(resid.lme, nb2listw(xy.rook), 999, na.action = na.exclude)
```

Plot Spatial dependence of residuals

```{r resid-cor-fig, message=FALSE, warning=FALSE}
library(purrr)
res.nn1 <- map_dbl(xy.rook, function(j) mean(resid.lme[j]))
  
c <- signif(cor(resid.lme, res.nn1, use = "pairwise.complete.obs"), 2)

plot(x = resid.lme, y = res.nn1, 
     main = paste0("r = ", c), xlab = "residual", ylab = "average residual of neighbor (rook)")

```

### Note on Geary's C

At this time, the **spdep** function `geary.test()` for Geary's C does not handle missing spatial points. This is area to contribute to! 
 
## Empirical variogram fitting

First, create a spatial object by adding spatial coordinates to an ordinary data frame. I like to use the actual size of the plots since they are often exaggerated rectangles (meters in this example).

```{r}
Nin.spatial <- Nin.na
coordinates(Nin.spatial) <- ~ col.width + row.length
class(Nin.spatial)
```

Set the maximum distance for calculating the variogram model (which is one-half the maximum distance between two points).

```{r}
max_dist = 0.6*max(dist(coordinates(Nin.spatial)))
max_dist
``` 

Calculate semivariance for an isotropic model and plot the variogram. 

```{r}
library(gstat)
resid.var1 <- variogram(yield ~ rep + gen, 
                        cutoff = max_dist,
                        width = max_dist/20, # 20 is the number of bins
                        data = Nin.spatial)
plot(resid.var1)
```

Test out correlated error models:

First, set the starting nugget values as the minimum of the semi-variance. There is likely more sophisticated methods to establish the starting value for nugget, but I have found that extracting the minimum value of the semivariance to work well as a starting point. 

```{r}
nugget_start <- min(resid.var1$gamma)
```

Establish models for variogram fitting. 
```{r}
Nin.vgm1 <- vgm(model = "Exp", nugget = nugget_start) # exponential
Nin.vgm2 <- vgm(model = "Sph", nugget = nugget_start) # spherical
Nin.vgm3 <- vgm(model = "Gau", nugget = nugget_start) # Gaussian
Nin.vgm4 <- vgm(model = "Mat", nugget = nugget_start) # Matern
```

Fit the variograms to the data:
```{r message=FALSE, warning=FALSE}
Nin.variofit1 <- fit.variogram(resid.var1, Nin.vgm1)
Nin.variofit2 <- fit.variogram(resid.var1, Nin.vgm2)
Nin.variofit3 <- fit.variogram(resid.var1, Nin.vgm3)
Nin.variofit4 <- fit.variogram(resid.var1, Nin.vgm4, fit.kappa = T)
```

### Compare variograms

Look at the results! (this is fun)

```{r}

plot(resid.var1, Nin.variofit1, main = "Exponential model")
plot(resid.var1, Nin.variofit2, main = "Spherical model")
plot(resid.var1, Nin.variofit3, main = "Gaussian model")
plot(resid.var1, Nin.variofit4, main = "Matern model")
```

How to pick the best one? Looking at how well each captures the error is the best approach. The attribute "SSError" indicates how well each model was able to predict the binned error terms as a function of distance. 

```{r}
print("Exponential"); attr(Nin.variofit1, "SSErr")
print("Spherical"); attr(Nin.variofit2, "SSErr")
print("Gaussian"); attr(Nin.variofit3, "SSErr")
print("Matern"); attr(Nin.variofit4, "SSErr")
```

`Nin.Variofit3` had the lowest error terms, corresponding to the Gaussian model.

Results from the empirical variogram:

```{r}
Nin.variofit3
```

The variogram parameters can be easily extracted from this table:

```{r}
nugget <- Nin.variofit3$psill[1] # "measurement error"
range <- Nin.variofit3$range[2] # distance to establish independence between data points
sill <- sum(Nin.variofit3$psill) # maximum semivariance
```

### Explore anisotropy

Most field experiments occur on a relatively small scale,where the entire experimental layout is less than 0.25 square miles. As such, isotropic models (where spatial correlation is based on distance but not direction) are often adequate for understanding localised field heterogeneity. However, there are always exceptions where a spatial correlation in a field trail is best describe by an anistropic model.  


Reestablish models for variogram fitting: 
```{r}
Nin.vgm1a <- vgm(model = "Exp", anis = c(90, 0.5)) # 90 refers to the angle of the main direction and 0.5 creates a second 90 degree axis of variability to estimate 
Nin.vgm2a <- vgm(model = "Sph", anis = c(90, 0.5))
Nin.vgm3a <- vgm(model = "Gau", anis = c(90, 0.5))

```

Fit the variograms to the data:
```{r message=FALSE, warning=FALSE, error=TRUE}
Nin.variofit1a <- fit.variogram(resid.var1, Nin.vgm1a)
Nin.variofit2a <- fit.variogram(resid.var1, Nin.vgm2a)
Nin.variofit3a <- fit.variogram(resid.var1, Nin.vgm3a)
Nin.variofit4a <- fit.variogram(resid.var1, Nin.vgm4a, fit.kappa = T)

print("Exponential"); attr(Nin.variofit1a, "SSErr")
print("Spherical"); attr(Nin.variofit2a, "SSErr")
print("Gaussian"); attr(Nin.variofit3a, "SSErr")

```

Error terms are considerably higher than in the isotropic model.

```{r}
plot(resid.var1, Nin.variofit1a, main = "Exponential model")
```

Hmm, that plot is not very convincing. 

In this field trial, there is evidence of spatial correlation as a function of distance, but there is not evidence this spatial correlation is impacted by direction.

**Another reminder on field trends**  

It's important to remember these methods are intended to describe localised spatial correlation. Field-wide spatial gradients, such as position on a slope, should be modelled as a separate trend. 


<!--chapter:end:04-example-identifying-spatial-var.Rmd-->

# Applying Spatial Analytical Techniques {#example-spatial-model}


Reload data if it is not already in your R environment: 

```{r message=FALSE, warning=FALSE}
library(agridat); library(dplyr); library(tidyr)
library(sp)

data("stroup.nin")

Nin <- stroup.nin %>% mutate(col.width = col * 1.2, 
                             row.length = row * 4.3) %>% 
  fill(rep, .direction = "up") %>%  arrange(col, row) 

Nin_na <- filter(Nin, !is.na(yield))
Nin_spatial <- Nin_na
coordinates(Nin_spatial) <- ~ col.width + row.length
```

Once spatial auto-correlation has been identified in field trials, the next step is to employ a modelling technique that will reduce the impact of spatial variation on the final estimates from the analysis.  

## Prep work

The first thing is to run a standard linear model. A common model specification for the randomised complete block design (RCBD) is to include cultivar as a fixed effect and block as a random effect. 

```{r message=FALSE, warning=FALSE}
library(nlme); library(emmeans)

nin.lme <- lme(yield ~ gen, random = ~1|rep,
              data = Nin,
              na.action = na.exclude)

# extract the least squares means for variety
preds.lme <- as.data.frame(emmeans(nin.lme, "gen"))
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(spdep)
xy.rook <- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type="rook") 
```

The variables "gen" refers to the cultivar or breeding line being trialled, and "rep" is the block, and the dependent variable, "yield" is grain yield. Basic exploratory analysis was conducted in \@ref(ch:ch3). 

## Correlated errors 

**Gaussian Example**

In order to fit models using correlated error model, we will need to first obtain preliminary estimates of the nugget, sill and range: from fitting an empirical variogram. 

```{r}
library(gstat)
max_dist <- 0.6*max(dist(coordinates(Nin_spatial)))
resid.var1 <- variogram(yield ~ rep + gen, 
                        cutoff = max_dist,
                        width = max_dist/29, 
                        data = Nin_spatial)
nugget_start <- min(resid.var1$gamma)
``` 

In the previous section, an isotropic Gaussian function was identified as the best model for describing the decay of error correlations over distance.

```{r}
Nin.vgm <- vgm(model = "Gau", nugget = nugget_start) 
Nin.variofit <- fit.variogram(resid.var1, Nin.vgm)

nugget <- Nin.variofit$psill[1] 
range <- Nin.variofit$range[2] 
sill <- sum(Nin.variofit$psill) 
nugget.effect <-  nugget/sill
```

Create a correlated error structure using the **nlme** package.
```{r}
cor.gaus <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "gaussian", 
                  metric = "euclidean")
```

Update the linear mixed model with the correlated error structure:
```{r}
nin.gaus <- update(nin.lme, corr = cor.gaus)
```

Extract variety estimates: 
```{r}
preds.gaus <- as.data.frame(emmeans(nin.gaus, "gen"))
```

Other models can be implemented quite similarly:

### Exponential

```{r}
rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect)

Nin.vgm <- vgm(model = "Exp", nugget = nugget_start) 
Nin.variofit <- fit.variogram(resid.var1, Nin.vgm)

nugget <- Nin.variofit$psill[1] 
range <- Nin.variofit$range[2] 
sill <- sum(Nin.variofit$psill) 
nugget.effect <-  nugget/sill

cor.exp <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "exponential", 
                  metric = "euclidean")

nin.exp <- update(nin.lme, corr = cor.exp)
preds.exp <- as.data.frame(emmeans(nin.exp, "gen"))
```

### Spherical

```{r}
rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect)

Nin.vgm <- vgm(model = "Sph", nugget = nugget_start) 
Nin.variofit <- fit.variogram(resid.var1, Nin.vgm)

nugget <- Nin.variofit$psill[1] 
range <- Nin.variofit$range[2] 
sill <- sum(Nin.variofit$psill) 
nugget.effect <-  nugget/sill

cor.sph <- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "spherical", 
                  metric = "euclidean")

nin.sph <- update(nin.lme, corr = cor.sph)
preds.sph <- as.data.frame(emmeans(nin.sph, "gen"))
```

### Power

```{r}
cor.pow <- corSpatial(form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = "ratio", 
                  metric = "euclidean")

nin.pow <- update(nin.lme, corr = cor.pow)
preds.pow <- as.data.frame(emmeans(nin.pow, "gen"))
```

In the **nlme** package, there is also an option for a linear model in the `corSpatial()` function. However, if a linear trend is present without a range or sill, it is recommended that a linear trend be fitted to the data instead. 

The package **spaMM** implements additional correlation models such as MatÃ©rn, Cauchy and more. 

```{r message=FALSE, warning=FALSE}
library(spaMM)

rm(Nin.vgm, Nin.variofit, nugget, sill, range, nugget.effect)
Nin.vgm <- vgm(model = "Mat", nugget = nugget_start) 
Nin.variofit <- fit.variogram(resid.var1, Nin.vgm, fit.kappa = TRUE)
 
nugget <- Nin.variofit$psill[1] 
range <- Nin.variofit$range[2] 
sill <- sum(Nin.variofit$psill) 
nugget.effect <-  nugget/sill
kappa <- Nin.variofit$kappa[2]

cor.mat <- corMatern(value = c(1/range, kappa, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  metric = "euclidean")
nin.matern <- update(nin.lme, corr = cor.mat)

preds.mat <- as.data.frame(emmeans(nin.matern, "gen"))
```

### AR1xAR1

The package **Sommer** implements a version of the AR1xAR1 covariance structure. However, it does not estimate the parameter $\rho$. The user must specify the $\rho$ and that value is not optimized in the restricted maximum likelihood estimation. There may be another way to implement the AR1xAR1 spatial model using the package **TMB**. Both SAS and Asreml can implement a mixed model with this covariance structure.


```{r message=FALSE, warning=FALSE}
library(sommer) 

Nin$colF <- as.factor(Nin$col)
Nin$rowF <- as.factor(Nin$row)

nin.ar1ar1 <- mmer(yield ~ gen,
                     random = ~ rep + 
                      vs(colF:rowF, Gu = kronecker(AR1(colF, rho=0.5), AR1(rowF, rho = 0.5), make.dimnames = TRUE)),
                   na.method.X = "include", na.method.Y = "exclude",
                   rcov = ~ units, data = Nin)

preds.ar1ar1 <- predict(nin.ar1ar1, classify = 'gen')$predictions %>% 
  rename(emmean = "predicted.value.yield", SE = "standard.errors.yield")
```

## Splines

The package **SpATS**, "spatial analysis for field trials", implements  B-splines for row and column effects. 
```{r message=FALSE, warning=FALSE}
library(SpATS)

# variables specifying row and column as factors are needed
Nin$colF <- Nin$R <- as.factor(Nin$col)
Nin$rowF <- Nin$C <- as.factor(Nin$row)

nin.spline <- SpATS(response = "yield", 
                    spatial = ~ PSANOVA(col, row, nseg = c(10,20),
                                        degree = 3, pord = 2), 
                    genotype = "gen",  
                    random = ~ rep + rowF + colF, 
                    data = Nin, control = list(tolerance = 1e-03))

preds.spline <- predict(nin.spline, which = "gen") %>% 
  dplyr::select(gen, emmean = "predicted.values", SE = "standard.errors")
```

Examine spatial trends: 
```{r}
plot(nin.spline)
```

## Spatial regression approaches

At this time, there are not suitable options for running spatial regression of variety trial data. Existing options in **spatialreg**, **spANOVA**, and **spaMM** are challenging to use, lack sufficient options for typical experimental design in variety trials and/or do not provide the desired output. 

<!--chapter:end:05-example-applying-spatial-covars.Rmd-->

# Comparing Spatial Models {#compare-model}

Now that we've built all these spatials models, how do we pick the right one? 

First, assemble all the model objects into one list.  
```{r message=FALSE, warning=FALSE}
library(purrr)
all.models <- mget(ls(pattern = "^nin.*"))
# print out their class
map(all.models, class)
```

## Spatial dependence of residuals

It would be helpful to know if these methods were effective in reducing the spatial dependence among the error residuals. 

The function below extracts the residuals from each model and is needed because of wonky handling of NA values by the packages **sommer** and **SpATS**. 

```{r message=FALSE, warning=FALSE}
L1 <- nrow(Nin)
non_na <- !is.na(Nin$yield)
L2 <- sum(non_na)

residuals <- map(all.models, function (x) {
  
  resids <- residuals(x)
  
  if(length(resids) == L2) {
    resids_pl = rep(NA, L1)
    resids_pl[non_na] = resids
    resids = resids_pl
  }
  return(resids)
})
```

Run Global Moran's I test on the extracted residuals:

```{r message=FALSE, warning=FALSE}
library(spdep)

xy.rook <- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), type="rook")

Moran.I <- map_df(residuals, function(x) {
  mi = moran.test(x, nb2listw(xy.rook), na.action = na.exclude)
  mi.stat <- mi$estimate
  mi.stat$p.value <- mi$p.value
  return(mi.stat)
}) %>% mutate(model = names(all.models)) %>% dplyr::select(c(5, 1:4)) %>% 
  mutate_at(2:5, round, 4) %>% arrange(p.value)

Moran.I
```

Only one model, `nin.spline` resulted in an improvement in Moran's I. Nearest neighbor approaches can also improve Moran's I. The significant p-values indicate that auto-correlation is still present in those models. However, that doesn't mean the other models are ineffective. The other models incorporate the spatial auto-correlation directly into the error terms. 

## Compare log likelihood

Since these are not nested models, likelihood ratio tests cannot be performed. Log likelihood can be compared within the models from **nlme** but not across packages since they use different estimation procedures.

```{r}
nlme.mods <- list(nin.lme, nin.exp, nin.gaus, nin.sph, nin.pow, nin.matern)

names(nlme.mods) <- c(c("lme", "exponential", "gaussian", 
                        "spherical", "power", "matern"))

lapply(nlme.mods, logLik)
```

Larger log likelihoods indicate a better fitting model to the data. A rule of thumb when comparing log likelihoods is that differences less than 2 are not considered notable. These results suggest that the Gaussian, spherical, power and MatÃ©rn models are substantially equivalent in capturing the variation present in this data set. 

## Compare changes in error

```{r}
exp.error <- lapply(nlme.mods, sigma)
exp.error
```

The overall experimental error, $\sigma$, increased in the correlated error models because field variation has been re-partitioned to the error when it was (erroneously) absorbed by the other experimental effects. 

As a result, the coefficient of variation is not a good metric for evaluating the quality of spatial models. 

```{r}
CV = lapply(nlme.mods, function(x) {
  sigma(x)/mean(fitted(x), na.rm = T) * 100
})
CV
```
I would further argue that, in general, the coefficient of variation is not an effective metric for evaluating confidence in variety trials. 

## Experimental power

Simulation studies indicate that incorporating spatial correlation into field trial analysis can improve the overall power of the experiment (the probability of detecting true differences in treatments). When working with data from an experiment, power is a transformed p-value. Performing ANOVA can indicate which approach maximizes power. 

```{r message=FALSE, warning=FALSE}
anovas <- lapply(nlme.mods, function(x){ 
  aov <- as.data.frame(anova(x))[2,]
  })

bind_rows(anovas) %>% mutate(model = c("lme", "exponential", "gaussian", 
                                            "spherical", "power", "matern")) %>% 
  arrange(desc(`p-value`)) %>% dplyr::select(c(5, 1:4))
```

This table indicates changes in the hypothesis test for "gen".  There is a dramatic change in power for this test when incorporating spatial covariance structures. 

## Standard error of variety estimates

Retrieve predictions generated in the previous section:
```{r}
all.preds <- mget(ls(pattern = "^preds.*"))
```

Extract standard errors and plot: 
```{r}
errors <- lapply(all.preds, "[", "SE")
pred.names <- gsub("preds.", "", names(errors))
error_df <- bind_cols(errors)
colnames(error_df) <- pred.names
```

```{r SE-box-fig, echo=FALSE, fig.cap='Differences in Variety Standard Error', out.width='80%', fig.asp=0.75, fig.align='center'}
boxplot(error_df, ylab = "standard errors", xlab = "linear model")
```

## Compare variety estimates

Extract estimates:
```{r}
preds <- lapply(all.preds, "[", "emmean")
preds_df <- bind_cols(preds)
colnames(preds_df) <- pred.names
preds_df$gen <- preds.exp$gen
```

Plot changes in ranks: 

```{r gen-ranks-fig, echo=FALSE, fig.align='center', fig.asp=0.75, fig.cap='Differences in Variety Ranks', message=FALSE, warning=FALSE, out.width='85%'}
library(ggplot2); library(reshape2)

lev <- c("lme", "exp", "gaus", "mat", "pow", "sph", "spline", "ar1ar1")

melt(preds_df, id.vars = "gen", variable.name = "model", value.name = "emmeans") %>% 
  mutate(model = factor(model, levels = lev)) %>% 
  ggplot(aes(x = model, y = emmeans, group = gen)) +
  geom_point() +
  geom_line() +
  ylab("yield means for gen") + 
  theme_minimal()
```

The black lines link the least squares means for a single variety. There is some consistency in the rankings between exponential, Gaussian, power, MatÃ©rn, and spherical covariance models. The control RCBD model, "lme", has fundamentally different rankings. The spline and AR1xAR1 ranking are also sightly different from the other models. 

Nevertheless, the following plot indicates considerable consensus in the least squares means from all of the spatial models. The upper diagonal contains Pearson correlations between those values. 

```{r ls-panel-fig, echo=FALSE, fig.align='center', fig.asp=1, fig.cap='Correlations in Variety Means', message=FALSE, warning=FALSE, out.width='90%'}
library(psych)
pairs.panels(preds_df[,-9], smooth = F, density = F, ellipses = F, 
             hist.col = "gold", pch = 1)
```

## Making decisions

There is no consensus on how to pick the best model. Some studies rely on log likelihood, while others seek to maximize the experimental power. Others have sought to minimize the root mean square error from cross validation.

The evidence suggest that for this data set, using any spatial model is better than running a naÃ¯ve RCBD model.  

<!--chapter:end:06-spatial-model-evaluation.Rmd-->

# Conclusion {#the-end}

## Other packages
There are many more other packages for exploring and modeling spatial variability in field trials. Some other useful packages available on CRAN:

|package |usage |
|-------------|-------------|
| Mcspatial | nonparametric spatial analysis |
|ngspatial | spatial models with a focus on generalised linear models |
|spaMM  | correlated error modes and generalised linear models |
|spANOVA | spatial analysis for field trials |

## Final recommendations

Spatial analysis is a big topic, but I think it is worth the effort to learn and implement in analysis of field trials. This guide provides some minimal recipes for how to incorporate spatial information into field trial statistical analysis. 

There is no denying that work is needed to develop scripts that automate this process so researchers can routinely incorporate spatial covariance into field trial analysis. Many current R tools are unwieldy to use and have insufficient options to support variety trial analysis.

Until this situation is improved, it is probably wisest to focus on using spatial models that are well-supported at this time. Any of the options implemented in the **nlme** package (or that work with that package) are decent choices with excellent support for extracting least-squares means, running ANOVA, and standard model diagnostics. Furthermore, **nlme** supports generalised linear models. 

Investigating spatial correlation in a field trial and controlling for it if necessary is recommended over doing nothing. 

<!--chapter:end:07-conclusion.Rmd-->


`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:08-references.Rmd-->

